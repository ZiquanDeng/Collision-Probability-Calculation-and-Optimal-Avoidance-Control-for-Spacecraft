\documentclass[10pt]{article}

\usepackage{framed,fancybox}
\usepackage{multicol,verbatim,overcite}
\usepackage[pdftex,colorlinks]{hyperref}
\hypersetup{%
colorlinks=true,
linkcolor=black,
urlcolor=cyan
}%
% \usepackage{palatino}
\usepackage{epsfig,enumerate,amsmath,amsfonts,latexsym,graphics,graphicx,theorem,graphics}
\usepackage{fancyhdr,subfig}
\usepackage{makeidx,amssymb,longtable}
\newcommand{\hs}[1]{\hspace*{ #1 mm}}
% \renewcommand{\bibname}{References}
% \renewcommand{\theequation}{\mbox{\thechapter--\arabic{equation}}}
\newcommand{\gpops}{{\em GPOPS}~}

\theorembodyfont{\upshape}

\pagestyle{fancy}
% \renewcommand{\chaptermark}[1]{\markboth{Chapter \thechapter{.}\: #1}{}}
% \renewcommand{\sectionmark}[1]{\markright{\thesection\ #1}}
\fancyhf{}
\fancyhead[LE,RO]{\small\bfseries\thepage}
\fancyhead[LO]{\small\bfseries\rightmark}
\fancyhead[RE]{\small\bfseries\leftmark}
\fancypagestyle{plain}{%
\fancyhead{} % get rid of headers
\renewcommand{\headrulewidth}{0pt} % and the line
}

\title{{\bf User's Manual for \gpops Version 5.0:} \vspace{12pt}\\
  {\bf A MATLAB$^{\textregistered}$ Software for Solving Multiple-Phase Optimal Control Problems Using $hp$--Adaptive Pseudospectral Methods}}
\author{Anil V.~Rao \\ {\em University of Florida} \\ Gainesville, FL 32607 \\ \\ David Benson \\ {\em The Charles Stark Draper Laboratory, Inc.} \\
  Cambridge, MA 02139 \\ \\ Christopher L.~Darby \\ Brendan Mahon \\ Camila Francolin \\ Michael Patterson \\ Ilyssa Sanders \\ {\em University of Florida} \\ Gainesville, FL 32607 \\ \\ Geoffrey T.~Huntington \\ {\em Blue Origin, LLC} \\ Seattle, WA \\ \\ 
\vspace{24pt} \\ August 2011}
\date{}

\oddsidemargin=0in
\evensidemargin=0in
\topmargin=1in
\hoffset=0in
\voffset=-1.5in
\textheight=9in
\textwidth=6.5in

\headwidth=\textwidth
\renewcommand{\headrulewidth}{0.25pt}
\raggedbottom


% \newcounter{example}[chapter]
% \newcounter{question}[chapter]
% {\theoremstyle{break}\theorembodyfont{\upshape}\newtheorem{example}{Example}[chapter]}
% {\theoremstyle{break}\theorembodyfont{\upshape}\newtheorem{solution}{Solution to Example}[chapter]}
% {\theoremstyle{plain}\theoremheaderfont{\normalsize\bfseries}\theorembodyfont{\upshape}\newtheorem{question}{\hspace{-0.25em}}[chapter]}

% \newcommand{\examplenumber}{\thechapter--\theexample}
% \renewcommand{\theexample}{\thechapter--\arabic{example}}
% \renewcommand{\thesolution}{\thechapter--\arabic{solution}}
% \renewcommand{\thequestion}{\thechapter--\arabic{question}}

%\newcommand{\ecaption}[1]{\addcontentsline{loe}{example}{\protect\numberline{\theexample}#1}}

% \renewcommand{\theequation}{\thechapter-\arabic{equation}}

\usepackage{color}

\definecolor{shadecolor}{gray}{0.99}
\FrameRule=0.75pt
\FrameSep=5pt
\setlength{\fboxrule}{\FrameRule}
\setlength{\fboxsep}{\FrameSep}

\newenvironment{ovalframe}{%
  \cornersize*{20pt}%
  \setlength{\fboxsep}{6pt}%
  \def\FrameCommand{\ovalbox}%
  \MakeFramed{\advance\hsize-\width \FrameRestore}}%
{\endMakeFramed}

\newenvironment{shadedframe}{%
  \def\FrameCommand{\fcolorbox{black}{shadecolor}}%
%  \MakeFramed {\addtolength{\hsize}{-\width}\FrameRestore}}
  \MakeFramed {\FrameRestore}}
{\endMakeFramed}

\newcommand{\bfblue}[1]{\textcolor{blue}{\bf #1}}
\newcommand{\slred}[1]{\textcolor{red}{\sl #1}}

\makeindex

\begin{document}

\setcounter{tocdepth}{1}

\input{shortcuts}

\maketitle
\clearpage

\section*{Acknowledgments}

The software \gpops was developed in response to a demand from
the research and academic community for a MATLAB software for solving
complex optimal control problems.  Since the original release of
\gpops in the Fall of 2008, the methods and the software have
undergone extensive changes.  Originally the software utilized the
Gauss pseudospectral method, but more research in the area of
pseudospectral methods for solving optimal control has led us to the
current version of the software that implements the Radau
pseudospectral method.  In addition, we now offer a code that
implements an $hp$--adaptive mesh refinement algorithm that
iteratively determines a mesh that accurately distributes the
collocation points.  The bulk of the changes to \gpops are internal,
that is, the user-interface has changed only slightly from earlier
versions of the code.  The authors of \gpops hope sincerely that the
code is useful.  

\section*{Disclaimer}

This software is provided ``as is'' and free-of-charge.  Neither the
authors nor their employers assume any responsibility for any harm
resulting from the use of this software.  The authors do, however,
hope that users will find this software useful for research and other
purposes.


\section*{Preface to The \gpops Software}

It is noted that \gpops has been designed to work with the nonlinear
programming solver SNOPT \cite{Gill1}.  The current version of \gpops
now includes a restricted version of SNOPT.  Next, \gpops has been
re-written so that now the objective function and constraint Jacobian
derivatives can be estimated using built-in finite-differencing, sparse
complex-step differentiation, or forward mode automatic
differentiation.  In addition, \gpops still retains the ability to use
the forward mode automatic differentiator {\em INTLAB}.  It is noted
that {\em INTLAB} can be downloaded from
\url{http://www.ti3.tu-harburg.de/rump/intlab/}.  Commercial use of
{\em INTLAB} requires a license which can be obtained by contacting
Professor Siegfried Rump via e-mail at rump\@tu-harburg.de.  

\section*{Changes in \gpops Version 5.0}

All of the changes in \gpops Version 5.0 are internal.  Specifically,
the mesh refinement method used in \gpops has been updated to be more
robust from that which was used in \gpops Version 4.x.  In addition,
the automatic scaling routine has been revised and this modification
has been found to work significantly better than the previous
automatic scaling routine.  It is noted that users of \gpops 4.x will
not see any changes in syntax to the software, but it is expected
(hoped) that this new version of \gpops will run more efficiently in
comparison to Version 4.x  

\section*{Licensing Agreement}

\input{gpopslicense.tex}

\clearpage
\setcounter{tocdepth}{2}
\tableofcontents

\clearpage

\section{Introduction to General Pseudospectral Optimization Software  (\gpops)}

{\em General Pseudospectral Optimization Software}
(\gpops) is a software program written in MATLAB\footnote{MATLAB is a
  registered trademark of The Mathworks, Inc., One Apple Hill, Natick,
  MA}${}^{\textregistered}$ for solving multiple-phase optimal control
problems of the following form.  Given a set of $P$ phases (where
$p=1,\ldots,P$), minimize the cost functional
\begin{equation}
  J = \sum_{p=1}^{P} J^{(p)} = \sum_{p=1}^{P}
  \left[\Phi^{(p)}(\bfx^{(p)}(t_0),t_0,\bfx^{(p)}(t_f),t_f;\bfq^{(p)})
  + \mcL^{(p)}(\bfx^{(p)}(t),\bfu^{(p)}(t),t;\bfq^{(p)})dt \right]
\end{equation}
subject to the dynamic constraint
\begin{equation}
  \dbfx^{(p)} = \bff^{(p)}(\bfx^{(p)},\bfu^{(p)},t;\bfq^{(p)}), \qquad (p=1,\ldots,P),
\end{equation}
the boundary conditions
\begin{equation}
  \bfphi_{\min} \leq
  \bfphi^{(p)}(\bfx^{(p)}(t_0),t_0^{(p)},\bfx^{(p)}(t_f),t_f^{(p)};\bfq^{(p)})
  \leq \bfphi_{\max}, \qquad (p=1,\ldots,P),
\end{equation}
the inequality path constraints
\begin{equation}
  \bfC_{\min}^{(p)} \leq \bfC^{(p)}(\bfx^{(p)}(t),\bfu^{(p)}(t),t;\bfq^{(p)})\leq  \bfC_{\max}^{(p)}, \qquad
  (p=1,\ldots,P),
\end{equation}
and the phase continuity (linkage) constraints
\begin{equation}
  \bfP^{(s)}(\bfx^{(p_l^s)}(t_f),t_f^{(p_l^s)};\bfq^{(p_l^s)},\bfx^{(p_u^s)}(t_0),t_0^{(p_u^s)};\bfq^{(p_u^s)})
  =   \bfzero, \qquad (p_l,p_u\in[1,\ldots,P],s=1,\ldots,L)
\end{equation}
where $\bfx^{(p)}(t)\in\bbR^{n_p}$, $\bfu^{(p)}(t)\in\bbR^{m_p}$,
$\bfq^{(p)}\in\bbR^{q_p}$, and $t\in\bbR$ are, respectively, the state,
control, static parameters, and time in phase $p\in[1,\ldots,P]$, $L$
is the number of phases to be linked,
$p_l^s\in[1,\ldots,P],\;(s=1,\ldots,L)$ are the ``left'' phase numbers,
and $p_u^s\in[1,\ldots,P],\;(s=1,\ldots,L)$ are the ``right'' phase
numbers.

While much of the time a user may want to solve a problem consisting of
multiple phases, it is important to note that the phases {\em need not
  be sequential}.  To the contrary, any two phases may be linked 
provided that the independent variable does not change direction (\ie the
independent variable moves in the same direction during each phase that is
linked).  A schematic of how phases can potentially be linked is given in
Fig.~\ref{fig: linkages}.
\begin{figure}[h]
  \centering
  \includegraphics[scale=0.95]{linkages.pdf}
  \caption{Schematic of linkages for multiple-phase optimal control problem.
    The example shown in the picture consists of five phases where the ends of
    phases 1, 2, and 3 are linked to the starts of phases 2, 3, and 4,
    respectively, while the end of phase 3 is linked to the start of phase 5.
    \label{fig: linkages}}
\end{figure}

\subsection{Radau Pseudospectral Method Employed by \gpops}

The method employed by \gpops is the {\em Radau Pseudospectral
Method} (RPM).  The RPM is an orthogonal collocation method where
the collocation points are the {\em Legendre-Gauss-Radau} points.  The
theory of the RPM can be found in
\cite{Garg1,Garg2,Garg3,Garg4,Patterson1}.  Some of the interesting
features of the RPM are as follows:  (1) it is a Gaussian quadrature
implicit integration scheme; (2) it has been demonstrated to converge
exponentially fast for problems whose solutions are smooth; (3) an
elegant connection exists between the continuous-time optimal control
problem and the discrete approximation; (4) it lends itself to the
$hp$--adaptive approach used in \gpops.  

\subsection{Organization of \gpops}

\gpops is organized as follows.  In order to specify the optimal control
problem that is to be solved, the user must write MATLAB functions that
define the following functions in each phase of the problem:
\begin{enumerate}[(1)]
  \item the cost functional
  \item the right-hand side of the differential equations and the path constraints(\ie the differential-algebraic equations)
  \item the boundary conditions (\ie event conditions)
  \item the linkage constraints (\ie how the phases are connected)
\end{enumerate}
In addition, the user must also specify the lower and upper limits on every component of the following quantities:
\begin{enumerate}[(1)]
  \item initial and terminal time of the phase
  \item the state at the following points in time:
    \begin{itemize}
    \item at the beginning of the phase
    \item during the phase
    \item at the end of the phase
    \end{itemize}
  \item the control
  \item the static parameters
  \item the path constraints
  \item the boundary conditions
  \item the phase duration (\ie total length of phase in time)
  \item the linkage constraints (\ie phase-connect conditions)
\end{enumerate}
It is noted that each of the functions must be defined for each phase
of the problem. The remainder of this document is devoted to describing in detail the
MATLAB${}^{\textregistered}$ syntax for describing the optimal control problem and each of the constituent functions.

\subsection{Notation Used Throughout Remainder of This Manual}

The following notation is adopted for use throughout the remainder of this
manual.  First, all user-specified names will be denoted by {\sl slanted}
characters (not {\em italic}, but {\sl slanted}).  Second, any item denoted by
{\bf boldface characters}  are pre-defined and cannot be changed by the user.
Finally, users with color capability will see the slanted characters in
\slred{red} and will see the boldface characters in \bfblue{blue}.

\subsection{Constructing an Optimal Control Problem in \gpops}

We now proceed to describe the constructs required to specify an
optimal control problem in \gpops.  We note that the key
MATLAB programming elements used in constructing an optimal control
problem in \gpops are {\em structure} and {\em arrays of structures}.

\subsection{Preliminary Information}

Before proceeding to the details of setting up a problem in
\gpops, the following few preliminary details are useful.  First,
it is important to understand that the \gpops interface is laid
out in {\bf\em phases}.  Using a phase-based approach, it is possible
to describe each segment of the problem independently of the other
segments.  The segments are then {\em linked} together using linkage
conditions (or phase-connect conditions).  Second, it is important to
note that \gpops uses the vectorization capabilities of MATLAB.
In this vein all matrices and vectors in \gpops are oriented
{\bf\em column-wise} for maximum efficiency.  As you read through
manual, please keep in mind the column-wise orientation of all
matrices used in \gpops.

\section{Constructing an Optimal Control Problem Using \gpops}

In this Section we provide the details of constructing a problem using
\gpops.  First, the call to \gpops is deceptively simple and is given as follows:
\begin{center}
\noindent{\bf [output,gpopsHistory]=gpops(setup)}
\end{center}
The input \slred{setup} is a user-defined structure that contains all
of the information about the optimal control problem to be solved
\footnote{see the detailed description of \slred{setup} in Section
\ref{sect:structureSyntax}}.  Finally, the variables \slred{output}
and \slred{gpopsHistory} are a structure and an array of structures
that contain, respectively,  the information on the final run of the
mesh refinement (\slred{output}) and a complete history of the
solutions on every mesh on which the problem was solved
(\slred{gpopsHistory}).\footnote{See the detailed description of the output in Section \ref{sect:output}.}.  

\subsection{Syntax for Input Structure \bfblue{setup}  \label{sect:structureSyntax}}

The user-defined structure \slred{setup} contains required fields and
optional fields.  The required fields in the structure \slred{setup}
are as follows:
\begin{itemize}
\item \bfblue{name}:  a string containing the name of the problem.
\item \bfblue{funcs}:  a structure whose elements contain the names
 of the user-defined function in the problem (see Section \ref{sect:funcNames} below).
\item \bfblue{limits}:  an array of structures that contains the
information about the lower and upper limits on the variables and
constraints in each phase of the problem (see Section \ref{sect:limits} below).
\item \bfblue{guess}:  an array of structures that contains
 contains a guess of the solution in each phase of the problem (see Section
 \ref{sect:guess} below).
\end{itemize} 
The optional fields (and their default values) are as follows:
\begin{itemize}
\item \bfblue{linkages}: an array of structures that contains the
 information about the lower and upper limits of the linkage constraints (see Section \ref{sect:linkages} below).
\item \bfblue{mesh}:  Specifies the parameters to be used by the
 $hp$--adaptive method refinement algorithm that is implemented in
 \gpops (see Section \ref{sect:mesh} below).
\item \bfblue{autoscale}: a string that indicates whether or not
 the user would like the optimal control problem to be scaled
 automatically before it is solved. (default=``off'') (see Section \ref{sect:scaling} below).
\item \bfblue{derivatives}:  a string indicating differentiation
  method to be used.  Possible values for this   string are
  ``finite-difference'', ``complex'', ``automatic'',
  ``automatic-INTLAB'', ``analytic'' (default=``finite-difference'')
  (see Section \ref{sect:derivatives} below). 
\item \bfblue{checkDerivatives}:  a flag to check user defined analytic derivatives (default=``0'') (see Section \ref{sect:derivatives} below).
\item \bfblue{maxIterations}:  a positive integer indicating the maximum number of iterations that can be taken by the NLP solver.  
\item \bfblue{printoff}:  a flag that will supress all printing from \gpops to the screen (default=``0'').
\item \bfblue{tolerances}:  two element array specifiying the NLP solver Optimality and Feasibility Tolerances (default=``[1e-6, 2e-6]'').
\end{itemize} 
Furthermore, it is important to note that \gpops has been designed so
that the independent variable must be monotonically {\em increasing'}
across each phase of the trajectory.  

\subsection{Syntax for Structure \bfblue{setup}.\bfblue{funcs} \label{sect:funcNames}}

The syntax for specifying the names of the MATLAB functions is done by
setting the fields in the structure \bfblue{FUNCS} and is given as follows:
\begin{displaymath}
  \begin{array}{lcl}
    \slred{setup}.\bfblue{funcs.cost} & = & \slred{`costfun.m'} \\
    \slred{setup}.\bfblue{funcs.dae} & = & \slred{`daefun.m'} \\
    \slred{setup}.\bfblue{funcs.event} & = & \slred{`eventfun.m'} \\
    \slred{setup}.\bfblue{funcs.link} & = & \slred{`linkfun.m'}
  \end{array}
\end{displaymath}

{\noindent}{\bf Example of Specifying Function Names for Use in \gpops}

\vspace{12pt}

{\noindent}Suppose we have a problem whose cost functional,
differential-algebraic equations, event constraints, and linkage
constraints are defined, respectively, via the \slred{user-defined}
functions \slred{mycostfun.m}, \slred{mydaefun.m},
\slred{myeventfun.m}, and \slred{mylinkfun.m}.  Then the syntax for
specifying these functions for use in \gpops is given as follows:
\begin{shadedframe}
\begin{verbatim}
setup.funcs.cost    = 'mycostfun';
setup.funcs.dae     = 'mydaefun';
setup.funcs.event   = 'myeventfun';
setup.funcs.link    = 'mylinkfun';
\end{verbatim}
\end{shadedframe}

\subsection{Syntax for \bfblue{limits} Structure \label{sect:limits}}

Once the user-defined structure \slred{setup} has been defined, the next
step in setting up a problem for use with \gpops is to create
an array of structures of length $P$ (where $P$ is the number of
phases) called \bfblue{limits}, where \bfblue{limits} is a
field of the structure \slred{setup}.  The array of structures
\bfblue{limits} is specified as follows:
\begin{itemize}
 \item \bfblue{limits($p$).meshPoints}: a monotonically increasing
  row vector of length $M_p,\; (p\in[1,\ldots,P])$, where each entry
  in the vector is on the domain $[-1,+1]$, that contains a set of
  mesh points for the initial run of \gpops.  If the user does not
  have an estimate of the mesh point locations, this field should be
  left blank.  
 \item \bfblue{limits($p$).nodesPerInterval}: a row vector of length
   $M_p-1,\; (p\in[1,\ldots,P])$, where each entry in the vector is a
   positive integer that contains the number of collocation points in
   each mesh interval for the initial run of \gpops.  If the user does not
  have an estimate of the number of collocation points in each mesh
  interval, this entry should be left blank.  
\item \bfblue{limits($p$).time.min} and \bfblue{limits($p$).time.max}:
   row vectors, each of length two, that contain the information
   about the lower and upper limits, respectively, on the initial and terminal time in phase
   $p\in[1,\ldots,P]$.  The row vectors
   \bfblue{limits($p$).time.min} and \bfblue{limits($p$).time.max} have the following form:
   \begin{displaymath}
     \begin{array}{lcl}
       \bfblue{limits(\textit{p}).time.min} & = & \left[\begin{array}{cc} t_0^{\textrm{min}} &
           t_f^{\textrm{min}} \end{array} \right] \\
       \bfblue{limits(\textit{p}).time.max} & = & \left[\begin{array}{cc} t_0^{\textrm{max}} &
           t_f^{\textrm{max}} \end{array} \right]
     \end{array}
   \end{displaymath}
 \item \bfblue{limits($p$).state.min} and \bfblue{limits($p$).state.max}:
   matrices, each of size $n_p \times 3$,
   that contain the lower and upper limits, respectively, on the
   state in phase $p\in[1,\ldots,P]$.  Each of the columns of the
   matrices \bfblue{limits($p$).state.min} and
   \bfblue{limits($p$).state.max} are given as follows:
   \begin{itemize}
     \item \bfblue{limits($p$).state.min(:,1)}: a column vector
       containing the lower (upper) limits on the state at the {\em
         start} of phase $p\in[1,\ldots,P]$.
     \item \bfblue{limits($p$).state.min(:,2)}: a column vector
       containing the lower (upper) limits on the state at the {\em
         during} phase $p\in[1,\ldots,P]$.
     \item \bfblue{limits($p$).state.min(:,3)}: a column vector
       containing the lower (upper) limits on the state at the {\em
         terminus} of phase $p\in[1,\ldots,P]$.
     \end{itemize}
     The matrices \bfblue{limits($p$).state.min} and
     \bfblue{limits($p$).state.max} then have the following form:
   \begin{displaymath}
     \begin{array}{lcl}
       \bfblue{limits(\textit{p}).state.min} & = & \left[\begin{array}{ccc} x_{10}^{\textrm{min}}
           & x_{1}^{\textrm{min}} & x_{1f}^{\textrm{min}} \\
           \vdots & \vdots & \vdots \\
           x_{n0}^{\textrm{min}} & x_{n}^{\textrm{min}} & x_{nf}^{\textrm{min}} \\
         \end{array} \right] \\ \\
       \bfblue{limits(\textit{p}).state.max} & = & \left[\begin{array}{ccc} x_{10}^{\textrm{max}}
           & x_{1}^{\textrm{max}} & x_{1f}^{\textrm{max}} \\
           \vdots & \vdots & \vdots \\
           x_{n0}^{\textrm{max}} & x_{n}^{\textrm{max}} & x_{nf}^{\textrm{max}} \\
         \end{array} \right]
     \end{array}
   \end{displaymath}
 \item \bfblue{limits($p$).control.min} and \bfblue{limits($p$).control.max}:  column vectors, each of length
   $m_p$, that contain the lower and upper limits, respectively, on the
   controls in phase $p\in[1,\ldots,P]$.  The column vectors
   \bfblue{limits($p$).control.min} and \bfblue{limits($p$).control.max}
   have the following form:
     \begin{displaymath}
       \begin{array}{lcl}
         \bfblue{limits(\textit{p}).control.min} & = & \left[\begin{array}{c} u_{1}^{\textrm{min}}
             \\ \vdots \\ u_{m}^{\textrm{min}} \end{array} \right] \\ \\
             \bfblue{limits(\textit{p}).control.max} & = & \left[\begin{array}{c} u_{1}^{\textrm{max}}
                 \\ \vdots \\ u_{m}^{\textrm{max}} \end{array} \right]
           \end{array}
       \end{displaymath}
 \item \bfblue{limits($p$).parameter.min} and
   \bfblue{limits($p$).parameter.max}:  column vectors, each of length
   $q_p$, that contain the lower and upper limits, respectively, on the static
   parameters in phase $p\in[1,\ldots,P]$.  The column vectors
   \bfblue{limits($p$).parameter.min} and \bfblue{limits($p$).parameters.max}
   have the following form:
     \begin{displaymath}
       \begin{array}{lcl}
         \bfblue{limits(\textit{p}).parameter.min} & = & \left[\begin{array}{c}
           q_{1}^{\textrm{min}} \\ \vdots \\ q_{q_p}^{\textrm{min}} \\
         \end{array} \right] \\ \\
       \bfblue{limits(\textit{p}).parameter.max} & = & \left[\begin{array}{c}
           q_{1}^{\textrm{max}} \\ \vdots \\ q_{q_p}^{\textrm{max}} \\
         \end{array} \right]
       \end{array}
     \end{displaymath}
 \item \bfblue{limits($p$).path.min} and \bfblue{limits($p$).path.max}: column vectors, each of length
   $r_p$, that contain the lower and upper limits, respectively, on the
   path constraints in phase $p\in[1,\ldots,P]$.   The column vectors
   \bfblue{limits($p$).path.min} and \bfblue{limits($p$).path.max}
   have the following form:
     \begin{displaymath}
       \begin{array}{lcl}
         \bfblue{limits(\textit{p}).path.min} & = & \left[\begin{array}{c}
           c_{1}^{\textrm{min}} \\ \vdots \\ c_{r_p}^{\textrm{min}} \\
         \end{array} \right] \\ \\
       \bfblue{limits(\textit{p}).path.max} & = & \left[\begin{array}{c}
           c_{1}^{\textrm{max}} \\ \vdots \\ c_{r_p}^{\textrm{max}} \\
         \end{array} \right]
       \end{array}
     \end{displaymath}
 \item \bfblue{limits($p$).event.min} and \bfblue{limits($p$).event.max}: column vectors, each of length
   $e_p$, that contain the lower and upper limits on the event
   constraints in phase $p\in[1,\ldots,P]$. The column vectors
   \bfblue{limits($p$).event.min} and \bfblue{limits($p$).event.max}
   have the following form:
   \begin{displaymath}
     \begin{array}{lcl}
       \bfblue{limits(\textit{p}).event.min} & = & \left[\begin{array}{c} \phi_{1}^{\textrm{min}}
           \\ \vdots \\ \phi_{e_p}^{\textrm{min}} \\
         \end{array} \right] \\ \\
       \bfblue{limits(\textit{p}).event.max} & = & \left[\begin{array}{c} \phi_{1}^{\textrm{min}}
           \\ \vdots \\ \phi_{e_p}^{\textrm{min}} \\
         \end{array} \right]
     \end{array}
   \end{displaymath}
 \item \bfblue{limits($p$).duration.min} and
   \bfblue{limits($p$).duration.max}: scalars that contain the lower
   and upper limits on the duration of phase $p\in[1,\ldots,P]$. The
   scalars \bfblue{limits($p$).duration.min} and
   \bfblue{limits($p$).duration.max} have the following form:
   \begin{displaymath}
     \begin{array}{lcl}
       \bfblue{limits(\textit{p}).duration.min} & = & T^{\min} \\
       \bfblue{limits(\textit{p}).duration.max} & = & T^{\max}
     \end{array}
   \end{displaymath}
 \item \bfblue{limits($p$).dependencies}: (optional) Matrix of size ($n_p$+$r_p$ x $n_p$+$m_p$) which 
   defines the dependencies of the dae functions on the state and control in phase $p\in[1,\ldots,P]$. 
   An entry of $1$ indicates that ode / path constraint corresponding to the row depends on 
   (i.e. has a non-zero derivative) the state / control corresponding to the column. An entry of $0$ 
   indicates no dependence. User specification of this matrix reduces the number of values in the 
   non-linear sparsity problem and can improve the solution time. A simple finite-difference check is 
   performed to avoid specifying no dependence if a dependence actually exists. (default=all-ones) 
\end{itemize}
{\noindent}{\bf Note:} any fields that do not apply to a problem (i.e. a problem without event constraints, path constraints, etc.) may be omitted or left as empty matrices (``[]'').

\scriptsize
\begin{shadedframe}
{\noindent}{\bf Example of Setting Up a Limits Structure}
\vspace{12pt}

As an example of setting up a limits structure in \gpops,
consider the following two-phase optimal control problem.  In
particular, suppose that {\em phase 1} of the problem has 3 states, 2
controls, 2 path constraints, and 5 event constraints.  Furthermore,
suppose in phase 1 that we choose to initialize \gpops with four mesh
points) at the locations $(-1,-1/3,1/3,+1)$ with $3$, $4$, and $5$
collocation points, respectively, in the first, second, and third mesh
intervals.  In addition, suppose that the lower and upper limits on
the initial and terminal time in the first phase are given as 
\begin{displaymath}
 \begin{array}{rcccr}
   0 & \leq  & t_0^{(1)} & \leq & 0 \\
   50 & \leq & t_f^{(1)} & \leq & 100
 \end{array}
\end{displaymath}
Next, suppose that the lower and upper limits on the states at the
{\em start} of the first phase are given, respectively, as
\begin{displaymath}
 \begin{array}{rcccr}
   1 & \leq & x_1(t_0^{(1)}) & \leq & 1 \\
   -3 & \leq & x_2(t_0^{(1)}) & \leq & 0 \\
   0 & \leq & x_2(t_0^{(1)}) & \leq & 5
 \end{array}
\end{displaymath}
Similarly, suppose that the lower and upper limits on the states
{\em during}  the first phase are given, respectively, as
\begin{displaymath}
 \begin{array}{rcccr}
   1 & \leq & x_1(t^{(1)}) & \leq & 10 \\
   -50 & \leq & x_2(t^{(1)}) & \leq & 50 \\
   -20 & \leq & x_2(t^{(1)}) & \leq & 20
 \end{array}
\end{displaymath}
Finally, suppose that the lower and upper limits on the states at the
{\em terminus} of the first phase are given, respectively, as
\begin{displaymath}
 \begin{array}{rcccr}
   5 & \leq & x_1(t_f^{(1)}) & \leq & 7 \\
   2 & \leq & x_2(t_f^{(1)}) & \leq & 2.5 \\
   -\pi & \leq & x_2(t_f^{(1)}) & \leq & \pi
 \end{array}
\end{displaymath}
Next, suppose that the lower and upper limits on the controls
{\em during} the first phase are given, respectively, as
\begin{displaymath}
 \begin{array}{rcccr}
   -50 & \leq & u_1(t^{(1)}) & \leq & 50 \\
   -100 & \leq & u_2(t^{(1)})& \leq & 100
 \end{array}
\end{displaymath}
Next, suppose that the lower and upper limits on the path constraints
{\em during} the first phase are given, respectively, as
\begin{displaymath}
 \begin{array}{rcccr}
   -10 & \leq & p_1(t^{(1)}) & \leq & 10 \\
    1 & \leq & p_2(t^{(1)})& \leq & 1
 \end{array}
\end{displaymath}
Next, suppose that the lower and upper limits on the event constraints
of the first phase are given, respectively, as
\begin{displaymath}
 \begin{array}{rcccr}
   0 & \leq & \phi_1^{(1)} & \leq & 1 \\
    -2 & \leq & \phi_2^{(1)} & \leq & 4 \\
   8 & \leq & \phi_3^{(1)} & \leq & 20 \\
   3 & \leq & \phi_4^{(1)} & \leq & 3 \\
   10 & \leq & \phi_5^{(1)} & \leq & 10
 \end{array}
\end{displaymath}
In a similar manner, suppose that {\em phase 2} of the problem
contains the following information:  4 states, 3 controls, 1 path constraint, and 4
event constraints.  Also, suppose that we choose to initialize \gpops
with a mesh consisting of six mesh points
$(-1,-0.75,-0.5,0,0.5,0.75,+1)$ with the $2$, $4$, $4$, $3$, and $2$
collocation points in the first through fifth mesh intervals,
respectively.  In addition, suppose now that the
lower and upper limits on the initial and terminal time in the first
phase are given, respectively, as
\begin{displaymath}
 \begin{array}{rcccr}
   50 & \leq  & t_0^{(2)} & \leq & 100 \\
   100 & \leq & t_f^{(2)} & \leq & 200
 \end{array}
\end{displaymath}
Next, suppose that the lower and upper limits on the states at the
{\em start} of the second phase are given, respectively, as
\begin{displaymath}
 \begin{array}{rcccr}
    3 & \leq & x_1(t_0^{(2)}) & \leq & 3 \\
   -10 & \leq & x_2(t_0^{(2)}) & \leq & 4 \\
   7 & \leq & x_3(t_0^{(2)}) & \leq & 18 \\
  25 & \leq & x_4(t_0^{(2)}) & \leq & 75
 \end{array}
\end{displaymath}
Similarly, suppose that the lower and upper limits on the states
{\em during} the second phase are given, respectively, as
\begin{displaymath}
 \begin{array}{rcccr}
   -200 & \leq & x_1(t^{(2)}) & \leq & 200 \\
   -50 & \leq & x_2(t^{(2)}) & \leq & 50 \\
   -20 & \leq & x_3(t^{(2)}) & \leq & 20 \\
   -80 & \leq & x_4(t^{(2)}) & \leq & 80
 \end{array}
\end{displaymath}
Finally, suppose that the lower and upper limits on the states at the
{\em terminus} of the second phase are given, respectively, as
\begin{displaymath}
 \begin{array}{rcccr}
   12 & \leq & x_1(t_f^{(2)}) & \leq & 12 \\
   -60 & \leq & x_2(t_f^{(2)}) & \leq & 30 \\
   -90 & \leq & x_3(t_f^{(2)}) & \leq & 10 \\
  100 & \leq & x_4(t_f^{(2)}) & \leq & 500
 \end{array}
\end{displaymath}
Next, suppose that the lower and upper limits on the controls
{\em during} the second phase are given, respectively, as
\begin{displaymath}
 \begin{array}{rcccr}
   -90 & \leq & u_1(t^{(2)}) & \leq & 90 \\
   -120 & \leq & u_2(t^{(2)})& \leq & 120
 \end{array}
\end{displaymath}
Next, suppose that the lower and upper limits on the path constraints
{\em during} the second phase are given, respectively, as
\begin{displaymath}
 \begin{array}{rcccr}
   -10 & \leq & p_1(t^{(2)}) & \leq & 10 \\
    1 & \leq & p_2(t^{(2)})& \leq & 1
 \end{array}
\end{displaymath}
Finally, suppose that the lower and upper limits on the events
constraints of the second phase phase are given, respectively, as
\begin{displaymath}
 \begin{array}{rcccr}
   0 & \leq & \phi_1^{(2)}  & \leq & 1 \\
    -2 & \leq & \phi_2^{(2)} & \leq & 4 \\
   8 & \leq & \phi_3^{(2)} & \leq & 20 \\
   3 & \leq & \phi_4^{(2)} & \leq & 3
 \end{array}
\end{displaymath}
Then a MATLAB code that would generate the above specification is
given as follows:
\begin{verbatim}
iphase = 1; % Set the phase number to 1
limits(iphase).meshPoints = [-1 -1/3 1/3 +1]; 
limits(iphase).nodesPerInterval = [3 4 5]; 
limits(iphase).time.min = [0 50];
limits(iphase).time.max = [0 100];
limits(iphase).state.min = [1 1 5; -3 -50 2; 0 -20 -pi];
limits(iphase).state.max = [1 10  7; 0  50 2.5; 5 20 pi];
limits(iphase).control.min = [-50; -100];
limits(iphase).control.max = [ 50;  100];
limits(iphase).parameter.min = [];
limits(iphase).parameter.max = [];
limits(iphase).path.min = [-10; 1];
limits(iphase).path.max = [10; 1];
limits(iphase).event.min = [0; -2; 8; 3; 10];
limits(iphase).event.max = [1; 4; 20; 3; 10];

iphase = 2; % Set the phase number to 2
limits(iphase).meshPoints = [-1 -0.75 -0.5 0.5 0.75 1];
limits(iphase).nodesPerInterval = [2 4 4 3 2];
limits(iphase).time.min = [50 100];
limits(iphase).time.max = [100 200];
limits(iphase).state.min = [3 -200 12; -10 -50 -60; 7 -20 -90; 25 -80 100];
limits(iphase).state.max = [3 200 12; 4 50 30; 18 20 10; 75 80 500];
limits(iphase).control.min = [-90; -120];
limits(iphase).control.max = [ 90;  120];
limits(iphase).parameter.min = [];
limits(iphase).parameter.max = [];
limits(iphase).path.min = [-10; 10];
limits(iphase).path.max = [1; 1];
limits(iphase).event.min = [0; -2; 8; 3];
limits(iphase).event.max = [1; 4; 20; 3];

setup.limits = limits;
\end{verbatim}
\end{shadedframe}
\normalsize
{\noindent}{\bf Note:}  in order to make the coding easier, we have
introduced the auxiliary integer variable{\bf iphase} so that the user
can more easily reuse code from phase to phase.

\subsection{Syntax for \bfblue{linkages} Array of Structures \label{sect:linkages}}

Another required field in the structure \slred{setup} is an array of
structures called \bfblue{linkages} that defines the way that the
phases are to be linked.  If there is only one phase in the problem, then
\slred{setup}.\bfblue{linkages} may be set to ``[]''.  If the problem
contains more than a single phase, then \bfblue{linkages} is an array
of structures of length $L$ (where $L$ is the number of pairs of phases
to be linked).  The array of structures \bfblue{linkages} is specified
as follows:
\begin{itemize}
\item \bfblue{linkages($s$).min}: a column vector of length $l_s$
  containing the lower limits on the $s^{th}$ pair of linkages.
\item \bfblue{linkages($s$).max}: a column vector of length $l_s$
  containing the upper limits on the $s^{th}$ pair of linkages.
\item \bfblue{linkages($s$).left.phase}: an integer containing the
  ``left'' phase in the pair of phases to be connected
\item \bfblue{linkages($s$).right.phase}: an integer containing the
  ``right'' phase in the pair of phases to be connected
\end{itemize}
Note that we use the terminology ``left'' and ``right'' in the sense
of viewing a graph of the trajectory on a page where time is
increasing to the right.  Thus, the ``left'' phase corresponds to the
terminus of a phase while the ``right'' phase corresponds to the
start of a phase.

\subsection{Syntax of Each Function Specified in Structure \bfblue{setup}.\bfblue{funcs}}

Now that we know {\em which} functions \gpops will use, the next step is to
discuss the syntax of each of these functions.  In general, the syntax for
each function will differ because the quantities being evaluated are different
in nature.  In this section we will explain the syntax of each function.

\subsection{Syntax of Cost Functional Specified in \bfblue{setup}.\bfblue{funcs}.\bfblue{cost}}\label{sect:costSyntax}

The syntax used to evaluate a user-defined cost functional is given as follows:
\begin{center}
\noindent{\bf function [Mayer,Lagrange]=mycostfun(solcost);}
\end{center}
{\noindent}where \slred{mycostfun.m} is the name of the MATLAB function,
\slred{solcost} is the input to the function, and
\slred{Mayer} and \slred{Lagrange} are the outputs.  The input
\slred{solcost} is a structure while the outputs
\slred{Mayer} and \slred{Lagrange} are the endpoint cost and the
integrand of the integrated cost, respectively.  The input structure
\slred{solcost} has the following fields (note that $N$=number of LGR points which are on the interior of the time interval):
\begin{itemize}
  \item \slred{solcost}.\bfblue{phase}:  the phase number
  \item \slred{solcost}.\bfblue{initial.time}:  the initial time in phase \slred{solcost}.\bfblue{phase}
  \item \slred{solcost}.\bfblue{initial.state}:  the initial state in phase \slred{solcost}.\bfblue{phase}
  \item \slred{solcost}.\bfblue{terminal.time}:  the terminal time in phase \slred{solcost}.\bfblue{phase}
  \item \slred{solcost}.\bfblue{terminal.state}:  the terminal state in phase \slred{solcost}.\bfblue{phase}
  \item \slred{solcost}.\bfblue{time}:  a column vector of length $N$ that
    contains the time (excluding the initial and terminal points) in
    phase \slred{solcost}.\bfblue{phase}
  \item \slred{solcost}.\bfblue{state}:  a matrix of size $N\times n$ (where $n$
    is the number of states) that contains the values of the state (excluding the initial and
    terminal points) in phase \slred{solcost}.\bfblue{phase}
  \item \slred{solcost}.\bfblue{control}:  a matrix of size $N\times m$ (where $m$
    is the number of controls) that contains the values of the control (excluding the initial and
    terminal points) in phase \slred{solcost}.\bfblue{phase}
  \item \slred{solcost}.\bfblue{parameter}:  a column vector of length $q$ that contains the values of the static parameters in phase \slred{solcost}.\bfblue{phase}
\end{itemize}
Finally, the outputs of \slred{mycostfun} are as follows:
\begin{itemize}
  \item \slred{Mayer}: a {\em scalar}, \ie size $1\times 1$
  \item \slred{Lagrange}: a {\em column} vector of size $N\times 1$
\end{itemize}

\noindent{\bf Warning About Outputs to Cost Function}

\vspace{10pt}

For many optimal control problems the output \slred{Lagrange} in the
user-defined cost function \slred{mycostfun} is {\bf\em zero}.  As such, it is
appealing to set \slred{Lagrange} to zero by the MATLAB command
\begin{equation}
  \textrm{Lagrange=0;}
\end{equation}
However, {\bf\em the integrand cannot be set to a scalar value!}.  Instead,
the integrand {\bf\em must} be set to a {\bf\em column vector of zeros!}.  The
way to set the integrand to zero and that {\bf\em will work in all cases} (\ie
finite-difference or automatic differentiation) is as follows:
\begin{equation}\label{integrand correct syntax zero}
  \boxed{
    \textrm{Lagrange=zeros(size(\slred{solcost}.\bfblue{time});}
  }
\end{equation}
The user is urged to use the syntax of Eq.~(\ref{integrand correct syntax zero})
whenever the integrand is identically zero.

\scriptsize
\begin{shadedframe}
{\noindent}{\bf Example of a Cost Functional}
\vspace{12pt}

Suppose we have a two-phase optimal control problem that uses a cost
functional named ``mycostfun.m''.  Suppose further that the dimension of the
state in each phase is 2 while the dimension of the control in each phase is
2.  Also, suppose that the endpoint and integrand cost in phase 1 are
given, respectively, as
\begin{displaymath}
  \begin{array}{lcl}
    \Phi^{(1)}(\bfx^{(1)}(t_0),t_0^{(1)},\bfx^{(1)}(t_f),t_f^{(1)}) & = & \bfx^T(t_f)\bfS\bfx(t_f) \\
    \mcL^{(1)}(\bfx^{(1)}(t),\bfu^{(1)}(t),t) & = & \bfx^T\bfQ\bfx + \bfu^T\bfR\bfu
  \end{array}
\end{displaymath}
while the endpoint and integrand in phase 2 are given, respectively, as
\begin{displaymath}
  \begin{array}{lcl}
    \Phi^{(2)}(\bfx^{(2)}(t_0^{(2)}),t_0^{(2)},\bfx^{(2)}(t_f^{(2)}),t_f^{(2)}) & = & \bfx^T(t_f)\bfx(t_f) \\
    \mcL^{(2)}(\bfx^{(2)}(t),\bfu^{(2)}(t),t) & = & \bfu^T\bfR\bfu
  \end{array}
\end{displaymath}
Then the syntax of the above cost functional is given as follows:
\begin{verbatim}
function [endpoint,integrand]=mycostfun(solcost);

Q = [5 0; 0 2];
R = [1 0; 0 3];
S = [1 5; 5 1];
iphase = solcost.phase;
t0 = solcost.initial.time;
x0 = solcost.initial.state;
tf = solcost.terminal.time;
xf = solcost.terminal.state;
t  = solcost.time;
x  = solcost.state;
u  = solcost.control;
p  = solcost.parameter;

if iphase==1,
  Mayer  = dot(xf,S*xf);
  Lagrange = dot(x,x*Q',2)+dot(u,u*R',2); % Note transposes
elseif iphase==2,
  Mayer  = dot(xf,xf);
  Lagrange = dot(u,u*R',2); % Note transposes
end;
\end{verbatim}
It is noted in the above function call that the third argument in the
command {\bf dot} takes the dot product across the {\em rows}, thereby
producing a {\em column vector}.
\end{shadedframe}
\normalsize

\subsection{Syntax for Differential-Algebraic Equations Function Specified in \bfblue{setup}.\bfblue{funcs}.\bfblue{dae} \label{sect:daeSyntax}}

The calling syntax used evaluate the right-hand side of a user-defined vector
of differential equations is given as follows:
\begin{center}
  \noindent{\bf function dae=mydaefun(soldae);}
\end{center}
{\noindent}where \slred{mydaefun.m} is the name of the MATLAB function,
\slred{soldae} is the input to the function, and
\slred{dae} is the output (\ie the right-hand side of the
differential equations and the values of the path constraints).  The
input \slred{soldae} is a structure while the output \slred{dae} is a
matrix of size $N \times (n+c)$ where $n$ is the number of
differential equations, $c$ is the number of path constraints, and $N$
is the number of LGR points.  The input structure \slred{soldae} has
the following fields:
\begin{itemize}
  \item \slred{soldae}.\bfblue{phase}:  the phase number
  \item \slred{soldae}.\bfblue{time}:  a column vector of length $N$ that
    contains the time (excluding the initial and terminal points) in phase \slred{soldae}.\bfblue{phase}
  \item \slred{soldae}.\bfblue{state}:  a matrix of size $N\times n$ (where $n$
    is the number of states) that contains the values of the state (excluding the initial and
    terminal points) in phase \slred{soldae}.\bfblue{phase}
  \item \slred{soldae}.\bfblue{control}:  a matrix of size $N\times m$ (where $m$
    is the number of controls) that contains the values of the control (excluding the initial and
    terminal points) in phase \slred{soldae}.\bfblue{phase}
  \item \slred{soldae}.\bfblue{parameter}:  a column vector of length $q$ that
    contains the values of the static parameters in phase \slred{soldae}.\bfblue{phase}
\end{itemize}
Finally, the output of \slred{myodefun} are as follows:
\begin{itemize}
  \item \slred{dae}: a {\em matrix} of size $N\times (n+c)$ containing
    the values of the right-hand side of the $n$ differential
    equations and the $c$ path constraints evaluated at the $N$ LGR points
\end{itemize}

\scriptsize
\begin{shadedframe}
{\noindent}{\bf Example of a Differential-Algebraic Equation}
\vspace{12pt}

Suppose we have a two-phase optimal control problem that uses a differential
equation function called ``mydaefun.m''.  Suppose further that the dimension
of the state in each phase is 2, the dimension of the control in each
phase is 2.  Furthermore, suppose that there are no path constraints
in phase 1 and one path constraint in phase 2.  Next, suppose that
the differential equations in phase 1 are given as
\begin{displaymath}
  \begin{array}{lcl}
    \dx_1 & = & -x_1^2-x_2^2 + u_1 u_2 \\
    \dx_2 & = & -x_1x_2 + 2(u_1+u_2)
  \end{array}
\end{displaymath}
Also, suppose that the differential equations in phase 2 are given as
\begin{displaymath}
  \begin{array}{lcl}
    \dx_1 & = & \sin(x_1^2+x_2^2) + u_1 u_2^2 \\
    \dx_2 & = & -\sin x_1 \cos x_2 + 2u_1u_2
  \end{array}
\end{displaymath}
Finally, suppose that the path constraint in phase 2 is given as
\begin{displaymath}
  u_1^2+u_2^2 = 1
\end{displaymath}
Then a MATLAB code that will evaluate the above system of
differential-algebraic equations is given as follows:
\begin{verbatim}
function dae = mydaefun(soldae);

iphase = soldae.phase;
t = soldae.time;
x = soldae.state;
u = soldae.control;
p = soldae.parameter;

if iphase==1,
  x1dot = -x(:,1).^2-x(:,2).^2 + u(:,1).*u(:,2);
  x2dot = -x(:,1).*x(:,2) + 2*(u(:,1)+u(:,2));
  path = [];
elseif iphase==2,
  x1dot = sin(x(:,1).^2 + x(:,2).^2) + u(:,1).*u(:,2).^2;
  x2dot = -sin(x(:,1)).*cos(x(:,2))+2*u(:,1).*u(:,2);
  path  = u(:,1).^2+u(:,2).^2;
end;
dae = [x1dot x2dot path];
\end{verbatim}
\end{shadedframe}
\normalsize

\subsection{Syntax of Event Constraint Function Specified in \bfblue{setup}.\bfblue{funcs}.\bfblue{event} \label{sect:eventSyntax}}

The syntax used to evaluate a user-defined vector of event constraints
is given as follows:
\begin{center}
\noindent{\bf function events=myeventfun(solevents,iphase);}
\end{center}
{\noindent}where \slred{myeventfun.m} is the name of the MATLAB function,
\slred{solevents} and \slred{iphase} are the inputs to the function, and
\slred{event} is the output (\ie the value of the event constraints).
The inputs \slred{solevents} and \slred{iphase} are a structure and
an integer, respectively, while the output \slred{event} is a
{\em column vector} of length $e$ where $e$ is the number of event
constraints.  The input structure \slred{solevents} has the following elements:
\begin{itemize}
  \item \slred{solevents}.\bfblue{phase}:  the phase number
  \item \slred{solevents}.\bfblue{initial.time}:  the time at the start of the phase
  \item \slred{solevents}.\bfblue{initial.state}:  the state at the start of the phase
  \item \slred{solevents}.\bfblue{terminal.time}:  the time at the terminus of the phase
  \item \slred{solevents}.\bfblue{terminal.state}:  the state at the terminus of the phase
  \item \slred{solevents}.\bfblue{parameter}:  the static parameters in the phase
\end{itemize}

\scriptsize
\begin{shadedframe}
{\noindent}{\bf Example of Event Constraints}
\vspace{12pt}

{\noindent}Suppose we have a one-phase optimal control problem that has two
initial event constraints and three terminal event constraints.  Suppose
further that the number of states in the phase is six and that the function
that computes the values of these constraints is called ``myeventfun.m''.
Finally, let the two initial event constraints be given as
\begin{displaymath}
  \begin{array}{lcl}
    \phi_{01} & = & x_1(t_0)^2+x_2(t_0)^2+x_3(t_0)^2 \\
    \phi_{02} & = & x_4(t_0)^2+x_5(t_0)^2+x_6(t_0)^2
  \end{array}
\end{displaymath}
while the three terminal event constraints are given as
\begin{displaymath}
  \begin{array}{lcl}
    \phi_{f1} & = & \sin(x_1(t_f))\cos(x_2(t_f)+x_3(t_f)) \\
    \phi_{f2} & = & \tan(x_4^2(t_f)+x_5^2(t_f)+x_6^2(t_f)) \\
    \phi_{f3} & = & x_4(t_f)+x_5(t_f)+x_6(t_f)
  \end{array}
\end{displaymath}
Then the syntax of the above event function is given as
\begin{verbatim}
function events = myeventfun(solevents);

iphase = solevents.phase;
t0 = solevents.initial.time;
x0 = solevents.initial.state;
tf = solevents.terminal.time;
xf = solevents.terminal.state;

ei1 = dot(x0(1:3),x0(1:3));
ei2 = dot(x0(4:6),x0(4:6));
ef1 = sin(xf(1))*cos(xf(2)+xf(3));
ef2 = tan(dot(xf(4:6),xf(4:6)));
ef3 = xf(4)+xf(5)+xf(6);

events = [ei1;ei2;ef1;ef2;ef3];
\end{verbatim}
\end{shadedframe}
\normalsize

Finally, it is noted that each event constraint need not be a function of
either the initial or the terminal state, but can also be functions that
contain {\em both} the initial and terminal state and/or the initial and
terminal time.  As an example of an event constraint that contains both the
initial and terminal state, consider the following example.

\scriptsize
\begin{shadedframe}
{\noindent}{\bf Example of Event Constraint Containing Both Initial and Terminal State}
\vspace{12pt}

{\noindent}Suppose we have a one-phase optimal control problem that contains
only a single state.  Furthermore, suppose that the problem contains a single
event constraint on the {\em difference} between the terminal value of the
state and the initial value of the state.  Finally, suppose that the function
that computes the values of these constraints is called ``myeventfun.m''.
Then the event constraint is evaluated as
\begin{displaymath}
  \phi = x(t_f)-x(t_0)
\end{displaymath}
Then the syntax of the above event function is given as
\begin{verbatim}
function events = myeventfun(solevents);

t0 = solevents.initial.time;
x0 = solevents.initial.state;
tf = solevents.terminal.time;
xf = solevents.terminal.state;

events = xf-x0;
\end{verbatim}
\end{shadedframe}
\normalsize

\subsection{Syntax of Linkage Constraint Function Specified in \bfblue{setup}.\bfblue{funcs}.\bfblue{link}\label{sect:linkSyntax}}

The syntax used to define the user defined vector of linkage constraints between two phases is given as follows:
\begin{center}
\noindent{\bf function links=mylinkfun(sollink);}
\end{center}
{\noindent}where \slred{mylinkfun.m} is the name of the MATLAB function,
\slred{sollink} is the input to the function, and \slred{links} is the output (\ie the value of the linkage
constraints).  The input \slred{sollink} is a structure while the output \slred{links} is a {\em column vector} of length $l$,
where $l$ is the number of event constraints. The input structure \slred{sollink} has the following fields:
\begin{itemize}
  \item \slred{sollink}.\bfblue{left.phase}:  the left phase of the
    pair of phases to be linked
  \item \slred{sollink}.\bfblue{right.phase}:  the right phase of the pair of phases to be linked
  \item \slred{sollink}.\bfblue{left.state}: the state at the terminus of phase \slred{sollink}.\bfblue{left.phase}
  \item \slred{sollink}.\bfblue{right.state}: the state at the start of phase \slred{sollink}.\bfblue{right.phase}
  \item \slred{sollink}.\bfblue{left.parameter}: the static parameters in phase \slred{sollink}.\bfblue{left.phase}
  \item \slred{sollink}.\bfblue{right.state}: the static parameters in phase \slred{sollink}.\bfblue{right.phase}
\end{itemize}
The terms {\em left} and {\em right} are conventions adopted to help
the user orient the phases on a page from left to right.

\scriptsize
\begin{shadedframe}
{\noindent}{\bf Example of Linkage Constraint}
\vspace{12pt}

{\noindent}Suppose we have a multiple phase optimal control problem with a simple link between the phases, i.e. the state of the end of the phase is equal to the state at the beginning of the next phase.  \begin{displaymath}
\bfP = x^l(t_f) - x^r(t_0)
\end{displaymath}
Then the syntax of the above linkage is given as
\begin{verbatim}
function links = mylinkagefun(sollink);

left_phase = sollink.left.phase;
right_phase = sollink.right.phase;
xf_left = sollink.left.state;
p_left  = sollink.left.parameter;
x0_left = sollink.right.phase;
p_left  = sollink.right.parameter;

links = xf_left - x0_right;
\end{verbatim}
\end{shadedframe}
\normalsize

\subsection{Specifying an Initial Guess of The Solution \label{sect:guess}}

The field \bfblue{guess} of the user-defined structure \slred{setup}
contains the initial guess for the problem.  The field
\bfblue{guess} is an array of structures of length $P$ (where $P$ is the
number of phases in the problem).  The $p^{th}$ element of the array
of structures \bfblue{guess} contains the initial guess of the problem in phase
$p\in[1,\ldots,P]$.  The fields of each element of array of structures
\bfblue{guess} are given as follows:
\begin{itemize}
\item \bfblue{guess(\textit{p}).time}:  a {\em column} vector of
  length $s$ where $s$ is the number of time points used in the guess
\item \bfblue{guess(\textit{p}).state}:  a matrix of size $s \times n$
  where $s$ is the number of time points and $n$ is the number of
  states in the phase
\item \bfblue{guess(\textit{p}).control}:  a matrix of size $s \times m$
  where $s$ is the number of time points and $m$ is the number of controls in the phase
\item \bfblue{guess(\textit{p}).parameter}:  a column vector of length $q$
  where $q$ is the number of static parameters in the phase
\end{itemize}
It is noted that the element \bfblue{guess(\textit{p}).time} must be
monotonically {\em increasing}.  Schematically, in each phase of the
problem the guess for the time, states, controls, and parameters is
structured as follows: 
\begin{displaymath}
  \begin{array}{lcl}
    \bfblue{guess(\textit{p}).time} & = &
    \left[\begin{array}{c} t_0 \\ t_1 \\ t_2 \\ \cdots \\
        t_{s} \end{array} \right] \\ \\
    \bfblue{guess(\textit{p}).state} & = &
    \left[\begin{array}{cccc} x_{10} & x_{20} & \cdots & x_{n0} \\
        x_{11} & x_{21} & \cdots & x_{n1} \\
        \vdots & \vdots & \vdots & \vdots \\
        x_{1s} & x_{2s} & \cdots & x_{ns}
        \end{array} \right] \\ \\
    \bfblue{guess(\textit{p}).control} & = &
    \left[\begin{array}{cccc} u_{10} & x_{20} & \cdots & x_{m0} \\
        u_{11} & u_{21} & \cdots & x_{m1} \\
        \vdots & \vdots & \vdots & \vdots \\
        u_{1s} & u_{2s} & \cdots & u_{ms}
        \end{array}
      \right] \\ \\
    \bfblue{guess(\textit{p}).parameter} & = &
    \left[\begin{array}{c} q_1 \\ q_2 \\ \vdots \\ q_q \end{array} \right]
  \end{array}
\end{displaymath}

\scriptsize
\begin{shadedframe}

{\noindent}{\bf Example of Specifying an Initial Guess}

\vspace{12pt}
Suppose we have a two-phase problem that has three states and two controls in
phase 1 while it has two states and one control in phase 2.  Furthermore,
suppose that we choose five time points for the guess in phase 1 while we
choose 3 time points for the guess in phase 2.  A MATLAB code that would
create such an initial guess is given below.
\begin{verbatim}

iphase = 1;
guess(iphase).time  = [0; 1; 3; 5; 7];
guess(iphase).state(:,1) = [1.27; 3.1; 5.8; 9.6; -13.7272];
guess(iphase).state(:,2) = [-4.2; -9.6; 8.5; 25.73; 100.00];
guess(iphase).state(:,3) = [18.727; 1.827; 25.272; -14.272; 26.84];
guess(iphase).control(:,1) = [8.4; -13.7; -26.5; 19; 87];
guess(iphase).control(:,2) = [-1.2; 5.8; -3.77; 14; 19.787];
guess(iphase).parameter = [];

iphase = 2;
guess(iphase).time = [7; 7.5; 8];
guess(iphase).state(:,1) = [0.5; 1.5; 8];
guess(iphase).state(:,2) = [-0.5; -2.5; 19];
guess(iphase).control(:,1) = [8.4; -13.7; -26.5; 19; 87];
guess(iphase).parameter = [];

setup.guess = guess;

\end{verbatim}
\end{shadedframe}
\normalsize 
It is noted again that, for the above example, auxiliary integer
variables were used to minimize the cumbersomeness of coding and to
minimize the chance of error.

\subsection{Scaling of Optimal Control Problem\label{sect:scaling}}

As with any numerical optimization procedure, the approach employed by
\gpops requires a well-scaled optimal control problem.  In general, it is
recommended that the user scale the problem in accordance with any known large
discrepancies either in the sizes of various quantities (\ie state, control)
or the sizes of the derivatives of such quantities.  While it is beyond the
scope of this user's manual to provide a general procedure for scaling, in an
attempt to reduce the burden on the user an automatic scaling procedure has
been developed for use in \gpops.  This procedure is based on the scaling
algorithm developed in \cite{Betts1}.  In order to invoke the automatic
scaling routine, the user must set the field \bfblue{autoscale} in the
user-defined structure \slred{setup} to the string ``on''.

The automatic scaling procedure operates as follows.  The bounds on the
variables are used to scale all components of the state, control, parameters,
and time to lie between -1 and 1.  As a result, it is essential that the user
provide {\em sensible} bounds on all quantities (\eg do not provide
unreasonably large bounds as this will result in a poorly scaled problem).
Next, the constraints are scaled to make the row norms of the Jacobians of the
respective functions approximately unity.  The automatic scaling procedure is
by no means foolproof, but it has been found in practice to work well on many
problems that otherwise would require scaling by hand.  The advice given here
is to try the automatic scaling procedure, but not to use it for too long if
it is proving to be unsuccessful.

\section{Specification of Parameters for Mesh Refinement\label{sect:mesh}}

An $hp$--adaptive mesh refinement algorithm is now included as part of
\gpops.  While the user does not need to provide any parameters in
order to use this algorithm, supplying values for these parameters is
recommended.  The mesh refinement algorithm parameters are specified
in the structure \slred{setup}.\bfblue{mesh} and are given as follows
(with the default values shown in the parentheses): 
\begin{itemize}
\item \bfblue{tolerance}:  a scalar real number containing the mesh
 refinement tolerance ({\bf default: }\bfblue{mesh}.\bfblue{tolerance}=$10^{-3}$).  
\item \bfblue{iteration}:  a positive integer containing the 
 number of mesh refinement iterations to perform ({\bf default: }\bfblue{mesh}.\bfblue{iteration}=$10$).  
\item \bfblue{nodesPerInterval}:  a structure containing the fields
  \bfblue{min} and \bfblue{max}, where \bfblue{min} and \bfblue{max}
  are integers containing the minimum and maximum number of allowable
  collocation points in a mesh interval ({\bf defaults: }
  \bfblue{nodesPerInterval}.\bfblue{min}=$4$ and \bfblue{nodesPerInterval}.\bfblue{max}=$12$).    
\item \bfblue{splitmult}:  a real number greater than or equal to
  unity that specified how quickly to increase the total number of
  segments in the mesh ({\bf default: }\bfblue{mesh}.\bfblue{splitmult}=$1.2$).  
\end{itemize}
It is noted that the user should use the default values until the
problem under consideration is reasonably well understood.   Finally,
if one wants to solve a problem with no mesh refinement and with a
specified mesh distribution, it is necessary to set
\slred{setup}.\bfblue{mesh}.\bfblue{iteration}=0 and provide the
necessary information in fields \bfblue{meshPoints} and
\bfblue{nodesPerInterval} of the \bfblue{limits} structure as
described in Section \ref{sect:limits}.  

\section{Different Options for Specification of Derivatives\label{sect:derivatives}}

The user has six choices for the computation of the derivatives of
the objective function gradient and the constraint Jacobian for use
within the NLP solver.  As stated above, the choices for
\bfblue{derivatives} are ``finite-difference'', ``complex'',
``automatic'', ``automatic-INTLAB'', and ``analytic'' and correspond
to the following differentiation methods: 
\begin{itemize}
\item \slred{setup}.\bfblue{derivatives}=``finite-difference'':
 default internal sparse finite-differencing algorithm is used.  
\item \slred{setup}.\bfblue{derivatives}=``complex'': the {\em
   built-in} complex-step differentiation method is used.
\item \slred{setup}.\bfblue{derivatives}=``automatic'', the {\em
    built-in} automatic differentiator is used.
\item \slred{setup}.\bfblue{derivatives}=``automatic-INTLAB'':
 automatic differentiation using the third-party program  {\em
   INTLAB} is used (if the program INTLAB is installed on your computer).
\item \slred{setup}.\bfblue{derivatives}=``analytic'': analytic derivatives
(supplied by the user) are used.
\end{itemize}
It is noted that INTLAB can be obtained from Prof.~Siegfried Rump by
visiting the URL \url{http://www.ti3.tu-harburg.de/rump/intlab/}.  

\subsection{Complex-Step Differentiation}

Of the differention methods given above, either the built-in automatic
differentiator or the complex-step differentiator most preferred
because these two methods provide highly accurate derivatives and are
both included as part of the \gpops software (\ie the user
does not have to obtain any third-party software). One drawback with
complex-step differentiation, however, is that certain functions need
to be handled with great care.  In particular, the functions {\bf
  min}, {\bf max}, {\bf abs}, and {\bf dot} need to be redefined for
use in complex-step differentiation (see Ref.~\citen{Martins1} and the URL
\url{http://mdolab.utias.utoronto.ca/resources/complex-step/complexify.f90}
for details).  Finally, the transpose operator must be replaced with a
dot-transpose (\ie a {\em real transpose}) because the standard
transpose in MATLAB produces a complex conjugate transpose and it is
necessary to maintain a real transpose when computing derivatives via
complex-step differentiation.

\subsection{Analytic Differentiation}

Analytic differentiation has the advantage that it is the fasted and
most accurate of the four methods, however, it is by far the most
complex for the user to compute, code, and verify.  The derivatives
for the objective function gradient and the constraint Jacobian are
computed from the user defined analytic derivatives.  These
derivatives are supplied as an additional output of the user functions
for the cost, dae functions, event constraints, and linkage
constraints (if applicable).  The user defined derivatives can be
checked relative to a finite-difference approximation by setting the
flag \slred{setup}.\bfblue{checkDerivatives} equal to one. Upon
execution of \gpops, the derivatives will be computed at the user
supplied initial guess using a finite-difference approximation and
compared to the analytic derivatives with the results printed to the
screen.  It is recommended that the user run the derivative checking
algorithm a least one time to verify that the derivatives are correct,
however, it should be noted that the algorithm is not guaranteed to
find any incorrect derivatives.  The user must take special care to
ensure that the analytic derivatives are coded correctly in order to
take advantage of the speed and accuracy of analytic differentiation. 

\subsubsection{Syntax of Cost Function Using Analytic Derivatives}

The syntax used to evaluate the user-defined cost derivatives is given as follows:
\begin{center}
\noindent{\bf function [Mayer,Lagrange,DerivMayer,DerivLagrange]=mycostfun(solcost);}
\end{center}
See Section \ref{sect:costSyntax} for the definition of the regular inputs/outputs.
The additional outputs of \slred{mycostfun} are as follows:
\begin{itemize}
  \item \slred{DerivMayer}: a {\em row} vector of size $1\times (2n+2+q)$
  \item \slred{DerivLagrange}: a {\em matrix} of size $N\times (n+m+q+1)$
\end{itemize}
where $n$ is the number of states, $m$ is the number of controls, $q$
is the number of parameters, and $N$ is the number of LGR points in the
phase. The row vector \slred{DerivMayer} defines the partial
derivatives of the Mayer cost with respect to the initial state,
initial time, final state, final time, and finally the parameters: 
\begin{center}
\noindent{\bf DerivMayer = $\left[\displaystyle \pd{\Phi}{\bfx(t_0)} \quad \pd{\Phi}{t_0} \quad \pd{\Phi}{\bfx(t_f)} \quad \pd{\Phi}{t_f} \quad \pd{\Phi}{p}\right]$}
\end{center}
where 
\begin{equation}
 \begin{array}{rcl}
   \displaystyle   \pd{\Phi}{\bfx(t_0)} & \in & \mathbb{R}^{1\times n}\vspace{6pt}\\
   \displaystyle  \pd{\Phi}{t_0} & \in & \mathbb{R} \vspace{6pt}\\ 
   \displaystyle   \pd{\Phi}{\bfx(t_f)} & \in & \mathbb{R}^{1\times n}\vspace{6pt}\\
   \displaystyle  \pd{\Phi}{t_f} & \in & \mathbb{R}\vspace{6pt}\\ 
   \displaystyle  \pd{\Phi}{\bfp} & \in & \mathbb{R}^{1\times q}
\end{array}
\end{equation} 
The matrix \slred{DerivLagrange} defines the partial derivatives of the Lagrange cost with respect to the state, control, parameters, and time at each of the $N$ LGR points:
\begin{center}
\noindent{\bf DerivLagrange = $\left[\displaystyle \pd{\mcL}{\bfx} \quad \pd{\mcL}{\bfu} \quad \pd{\mcL}{t} \quad \pd{\mcL}{p} \right]$}
\end{center}
where
\begin{equation}
 \begin{array}{lcl}
\displaystyle   \pd{\mcL}{\bfx} & \in & \mathbb{R}^{N\times n}\vspace{6pt}\\
\displaystyle   \pd{\mcL}{\bfu} & \in & \mathbb{R}^{N\times m}\vspace{6pt}\\
\displaystyle   \pd{\mcL}{t} & = & \mathbb{R}^{N\times 1}\vspace{6pt}\\ 
\displaystyle  \pd{\mcL}{\bfp} & = & \mathbb{R}^{N\times q}
\end{array}
\end{equation}

It is important to provide all the derivatives in the correct order {\em even if} they are zero.

\scriptsize
\begin{shadedframe}
{\noindent}{\bf Example of a Cost Functional with Derivatives}
\vspace{12pt}

Suppose we have a two-phase optimal control problem that uses a cost
functional named ``mycostfun.m''.  Suppose further that the dimension of the
state in each phase is 2 while the dimension of the control in each phase is
2.  Also, suppose that the endpoint and integrand cost in phase 1 are
given, respectively, as
\begin{displaymath}
  \begin{array}{lcl}
    \Phi^{(1)}(\bfx^{(1)}(t_0),t_0^{(1)},\bfx^{(1)}(t_f),t_f^{(1)}) & = & \bfx^T(t_f)\bfS\bfx(t_f) \\
    \mcL^{(1)}(\bfx^{(1)}(t),\bfu^{(1)}(t),t) & = & \bfx^T\bfQ\bfx + \bfu^T\bfR\bfu
  \end{array}
\end{displaymath}
while the endpoint and integrand in phase 2 are given, respectively, as
\begin{displaymath}
  \begin{array}{lcl}
    \Phi^{(2)}(\bfx^{(2)}(t_0^{(2)}),t_0^{(2)},\bfx^{(2)}(t_f^{(2)}),t_f^{(2)}) & = & \bfx^T(t_f)\bfx(t_f) \\
    \mcL^{(2)}(\bfx^{(2)}(t),\bfu^{(2)}(t),t) & = & \bfu^T\bfR\bfu
  \end{array}
\end{displaymath}
Then the syntax of the above cost functional is given as follows:
\begin{verbatim}
function [Mayer,Lagrange,DerivMayer,DerivLagrange]=mycostfun(solcost,iphase);

Q = [5 0; 0 2];
R = [1 0; 0 3];
S = [1 5; 5 1];
t0 = solcost.initial.time;
x0 = solcost.initial.state;
tf = solcost.terminal.time;
xf = solcost.terminal.state;
t  = solcost.time;
x  = solcost.state;
u  = solcost.control;
p  = solcost.parameter;

if iphase==1,
  Mayer  = dot(xf,S*xf);
  Lagrange = dot(x,x*Q',2)+dot(u,u*R',2); % Note transposes
  DerivMayer = [zeros(1,length(x0)), zeros(1,length(t0)), ...
                xf'*S, zeros(1,length(tf), zeros(1,length(p))];
  DerivLagrange = [x*Q', u*R',zeros(size(t)), zeros(length(t),length(p))];
elseif iphase==2,
  Mayer  = dot(xf,xf);
  Lagrange = dot(u,u*R',2); % Note transposes
  DerivMayer = [zeros(1,length(x0)), zeros(1,length(t0)), xf', zeros(1,length(tf), zeros(1,length(p))];
  DerivLagrange = [zeros(size(x)), u*R', zeros(length(t),length(p)), zeros(size(t))];
end;
\end{verbatim}
It is noted in the above function call that the third argument in the
command {\bf dot} takes the dot product across the {\em rows}, thereby
producing a {\em column vector}.
\end{shadedframe}
\normalsize

\subsubsection{Syntax of Differential-Algebraic Equations Function Using Analytic Derivatives}

The calling syntax used evaluate the derivatives of the right-hand side of a user-defined vector
of differential equations is given as follows:
\begin{center}
  \noindent{\bf function [dae,Derivdae]=mydaefun(soldae);}
\end{center}
See Section \ref{sect:daeSyntax} for the definition of the regular inputs/outputs.
The additional output of \slred{myodefun} is as follows:
\begin{itemize}
  \item \slred{Derivdae}: a {\em matrix} of size $N(n+c) \times (n+m+q+1)$
\end{itemize}
where $n$ is the number of states, $m$ is the number of controls, $q$
is the number of parameters, $c$ is the number of path constraints,
and $N$ is the number of LGR points in the phase.  The matrix
\slred{Derivdae} defines the partial derivatives of the differential
equations and path constraints with respect to the state, control,
parameters, and time at each of the $N$ LGR points: 
\begin{center}
\noindent{\bf Derivdae = $\left[\begin{array}{cccc}
\displaystyle \pd{f_1}{\bfx} &\displaystyle\pd{f_1}{\bfu} & \displaystyle\pd{f_1}{t}& \displaystyle\pd{f_1}{\bfp}\vspace{6pt}\\
\vdots & \vdots & \vdots  &\vdots \vspace{6pt}\\
\displaystyle \pd{f_2}{\bfx} &\displaystyle\pd{f_2}{\bfu} &\displaystyle\pd{f_2}{t}& \displaystyle\pd{f_2}{\bfp}\vspace{6pt}\\
\vdots & \vdots & \vdots  &\vdots \vspace{6pt}\\
\displaystyle \pd{f_n}{\bfx} &\displaystyle\pd{f_n}{\bfu} &\displaystyle\pd{f_n}{t}& \displaystyle\pd{f_n}{\bfp}\vspace{6pt}\\
\displaystyle \pd{C_1}{\bfx} &\displaystyle\pd{C_1}{\bfu} &\displaystyle\pd{C_1}{t}& \displaystyle\pd{C_1}{\bfp}\vspace{6pt}\\
\vdots & \vdots & \vdots  &\vdots \vspace{6pt}\\
\displaystyle \pd{C_r}{\bfx} &\displaystyle\pd{C_r}{\bfu} &\displaystyle\pd{C_r}{t}& \displaystyle\pd{C_r}{\bfp}\vspace{6pt}\\
\end{array}\right]$}
\end{center}
where $f_i$, ($i = 1,\ldots,n$) is the right-hand side of the
$i^{th}$ differential equation, and $C_j$, ($j = 1,\ldots,r$) is
the $j^{th}$ path constraint.  Each of the elements of \slred{Derivdae}
have the following sizes:
\begin{equation}
  \begin{array}{rcl}
\displaystyle    \pd{f_i}{\bfx} & \in & \mathbb{R}^{N\times n}, \quad (i=1,\ldots,n)\vspace{6pt} \\
\displaystyle   \pd{f_i}{\bfu} & \in & \mathbb{R}^{N\times m}, \quad (i=1,\ldots,n) \vspace{6pt} \\
\displaystyle   \pd{f_i}{t} & \in & \mathbb{R}^{N\times 1}, \quad (i=1,\ldots,n) \vspace{6pt}\\
\displaystyle   \pd{f_i}{\bfp} & \in & \mathbb{R}^{N\times q}, \quad (i=1,\ldots,n) \vspace{6pt}\\
\displaystyle    \pd{C_i}{\bfx} & \in & \mathbb{R}^{N\times n}, \quad (i=1,\ldots,r) \vspace{6pt}\\
\displaystyle   \pd{C_i}{\bfu} & \in & \mathbb{R}^{N\times m}, \quad (i=1,\ldots,r) \vspace{6pt}\\
\displaystyle   \pd{C_i}{t} & \in & \mathbb{R}^{N\times 1}, \quad (i=1,\ldots,r) \vspace{6pt}\\
\displaystyle   \pd{C_i}{\bfp} & \in & \mathbb{R}^{N\times q}, \quad (i=1,\ldots,r) 
 \end{array}
\end{equation}

It is important to provide all the
derivatives in the correct order {\em even if} they are zero. 

\scriptsize
\begin{shadedframe}
{\noindent}{\bf Example of a Differential-Algebraic Equation with Derivatives}
\vspace{12pt}

Suppose we have a two-phase optimal control problem that uses a differential
equation function called ``mydaefun.m''.  Suppose further that the dimension
of the state in each phase is 2, the dimension of the control in each
phase is 2.  Furthermore, suppose that there are no path constraints
in phase 1 and one path constraint in phase 2.  Next, suppose that
the differential equations in phase 1 are given as
\begin{displaymath}
  \begin{array}{lcl}
    \dx_1 & = & -x_1^2-x_2^2 + u_1 u_2 \\
    \dx_2 & = & -x_1x_2 + 2(u_1+u_2)
  \end{array}
\end{displaymath}
Also, suppose that the differential equations in phase 2 are given as
\begin{displaymath}
  \begin{array}{lcl}
    \dx_1 & = & \sin(x_1^2+x_2^2) + u_1 u_2^2 \\
    \dx_2 & = & -\sin x_1 \cos x_2 + 2u_1u_2
  \end{array}
\end{displaymath}
Finally, suppose that the path constraint in phase 2 is given as
\begin{displaymath}
  u_1^2+u_2^2 = 1
\end{displaymath}
Then a MATLAB code that will evaluate the above system of
differential-algebraic equations is given as follows:
\begin{verbatim}
function [dae, Derivdae] = mydaefun(soldae);

iphase = soldae.phase;
t = soldae.time;
x = soldae.state;
u = soldae.control;
p = soldae.parameter;

if iphase==1,
  x1dot = -x(:,1).^2-x(:,2).^2 + u(:,1).*u(:,2);
  x2dot = -x(:,1).*x(:,2) + 2*(u(:,1)+u(:,2));
  path = [];
  df1_dx1 = -2*x(:,1);
  df1_dx2 = -2*x(:,2);
  df1_du1 = u(:,2);
  df1_du2 = u(:,1);
  df2_dx1 = -x(:,2);
  df2_dx2 = -x(:,1);
  df2_du1 = 2*ones(size(t));
  df2_du2 = 2*ones(size(t));
  dpath_dx1 = [];
  dpath_dx2 = [];
  dpath_du1 = [];
  dpath_du2 = [];
  dpath_dp = [];
  dpath_dt = [];
elseif iphase==2,
  x1dot = sin(x(:,1).^2 + x(:,2).^2) + u(:,1).*u(:,2).^2;
  x2dot = -sin(x(:,1)).*cos(x(:,2)) + 2*u(:,1).*u(:,2);
  path  = u(:,1).^2+u(:,2).^2;
  df1_dx1 = 2*x(:,1)*cos(x(:,1).^2 + x(:,2).^2);
  df1_dx2 = 2*x(:,2)*cos(x(:,1).^2 + x(:,2).^2);
  df1_du1 = u(:,2).^2;
  df1_du2 = 2*u(:,1).*u(:,2);
  df2_dx1 = -cos(x(:,1)).*cos(x(:,2));
  df2_dx2 = sin(x(:,1)).*sin(x(:,2));
  df2_du1 = 2*u(:,2);
  df2_du2 = 2*u(:,1);
  dpath_dx1 = zeros(size(x(:,1)));
  dpath_dx2 = zeros(size(x(:,2)));
  dpath_du1 = 2*u(:,1);
  dpath_du2 = 2*u(:,2);
  dpath_dp = zeros(length(t),length(p));
  dpath_dt = zeros(size(t));
end;
df1_dp = zeros(length(t),length(p));
df1_dt = zeros(size(t));
df2_dp = zeros(length(t),length(p));
df2_dt = zeros(size(t));

dae = [x1dot x2dot path];

Derivdae = [df1_dx1,   df1_dx2,   df1_du1,   df1_du2,   df1_dt,   df1_dp; ...
            df2_dx1,   df2_dx2,   df2_du1,   df2_du2,   df2_dt    df2_dp,; ...
          dpath_dx1, dpath_dx2, dpath_du1, dpath_du2, dpath_dt,  dpath_dp,];
\end{verbatim}
\end{shadedframe}
\normalsize

\subsubsection{Syntax of Event Constraint Function Using Analytic Derivatives}

The syntax used to evaluate the derivative of a user-defined vector of event constraints
is given as follows:
\begin{center}
\noindent{\bf function [events, Derivevents]=myeventfun(solevents);}
\end{center}
See Section \ref{sect:eventSyntax} for the definition of the regular inputs/outputs.  The additional output of \slred{myeventfun} is as follows:
\begin{itemize}
  \item \slred{Derivevents}: a {\em matrix} of size $e\times (2n+2+q)$
\end{itemize}
where $n$ is the number of states, $q$ is the number of parameters, and $e$ is the number of event constraints in the phase.  The matrix \slred{Derivevents} defines the partial derivatives of each event constraint with respect to the initial state, initial time, final state, final time, and parameters:
\begin{center}
\noindent{\bf Derivevents = $\left[\begin{array}{rrrrr}
\displaystyle \pd{\phi_1}{\bfx(t_0)}, &\quad \displaystyle\pd{\phi_1}{t_0}, &\quad \displaystyle\pd{\phi_1}{\bfx(t_f)}, &\quad \displaystyle\pd{\phi_1}{t_f}, &\quad \displaystyle\pd{\phi_1}{p} \vspace{6pt}\\
 \vdots, &\quad \vdots, &\quad \vdots, &\quad \vdots, &\quad \vdots \vspace{6pt}\\
\displaystyle \pd{\phi_e}{\bfx(t_0)}, &\quad \displaystyle\pd{\phi_e}{t_0}, &\quad \displaystyle\pd{\phi_e}{\bfx(t_f)}, &\quad \displaystyle\pd{\phi_e}{t_f}, &\quad \displaystyle\pd{\phi_e}{p}
\end{array}\right]$}
\end{center}
where $\phi_i$, ($i = 1,\ldots,e$) is the $i^{th}$ event constraint.
The sizes of each of the entries in \slred{Derivevents} are as
follows:
\begin{equation}
 \begin{array}{rcl}
\displaystyle   \pd{\phi_i}{\bfx(t_0)} & \in & \mathbb{R}^{1\times n}\vspace{6pt}\\
\displaystyle  \pd{\phi_i}{t_0} & \in & \mathbb{R} \vspace{6pt}\\ 
\displaystyle   \pd{\phi_i}{\bfx(t_f)} & \in & \mathbb{R}^{1\times n}\vspace{6pt}\\
\displaystyle  \pd{\phi_i}{t_f} & \in & \mathbb{R}\vspace{6pt}\\ 
\displaystyle  \pd{\Phi}{\bfp} & \in & \mathbb{R}^{1\times q}
\end{array}, \quad (i=1,\ldots,e)
\end{equation} 
It is important to provide all the derivatives in the correct order {\em even if} they are zero.

\scriptsize
\begin{shadedframe}
{\noindent}{\bf Example of Event Constraints with Derivatives}
\vspace{12pt}

{\noindent}Suppose we have a one-phase optimal control problem that has two
initial event constraints and three terminal event constraints.  Suppose
further that the number of states in the phase is six and that the function
that computes the values of these constraints is called ``myeventfun.m''.
Finally, let the two initial event constraints be given as
\begin{displaymath}
  \begin{array}{lcl}
    \phi_{01} & = & x_1(t_0)^2+x_2(t_0)^2+x_3(t_0)^2 \\
    \phi_{02} & = & x_4(t_0)^2+x_5(t_0)^2+x_6(t_0)^2
  \end{array}
\end{displaymath}
while the three terminal event constraints are given as
\begin{displaymath}
  \begin{array}{lcl}
    \phi_{f1} & = & \sin(x_1(t_f))\cos(x_2(t_f)+x_3(t_f)) \\
    \phi_{f2} & = & \tan(x_4^2(t_f)+x_5^2(t_f)+x_6^2(t_f)) \\
    \phi_{f3} & = & x_4(t_f)+x_5(t_f)+x_6(t_f)
  \end{array}
\end{displaymath}
Then the syntax of the above event function is given as
\begin{verbatim}
function [events, Derivevents] = myeventfun(solevents);

iphase = solevents.phase;
t0 = solevents.initial.time;
x0 = solevents.initial.state;
tf = solevents.terminal.time;
xf = solevents.terminal.state;

ei1 = dot(x0(1:3),x0(1:3));
ei2 = dot(x0(4:6),x0(4:6));
ef1 = sin(xf(1))*cos(xf(2)+xf(3));
ef2 = tan(dot(xf(4:6),xf(4:6)));
ef3 = xf(4)+xf(5)+xf(6);

events = [ei1;ei2;ef1;ef2;ef3];

dei1_dx0 = [2*x0(1:3).' zeros(1,3)];
dei1_dt0 = 0;
dei1_dxf = zeros(1,6);
dei1_dtf = 0;
dei1_dp = [];
dei1_dt = 0;
dei2_dx0 = [zeros(1,3), 2*x0(4:6).'];
dei2_dt0 = 0;
dei2_dxf = zeros(1,6);
dei2_dtf = 0;
dei2_dp = [];
def1_dx0 = zeros(1,6);
def1_dt0 = 0;
def1_dxf = [cos(xf(1))*cos(xf(2)+xf(3)), -sin(xf(1))*sin(xf(2)+xf(3)), ...
           -sin(xf(1))*sin(xf(2)+xf(3)), zeros(1,3)];
def1_dtf = 0;
def1_dp = [];
def2_dx0 = zeros(1,6);
def2_dt0 = 0;
def2_dxf = [zeros(1,3), 2*xf(4:6).']/(cos(dot(xf(4:6),xf(4:6))))^2;
def2_dtf = 0;
def2_dp = [];
def3_dx0 = zeros(1,6);
def3_dt0 = 0;
def3_dxf = [zeros(1,3), ones(1,3)];
def3_dtf = 0;
def3_dp = [];

Derivevents = [dei1_dx0, dei1_dt0, dei1_dxf, dei1_dtf, dei1_dt, dei1_dp; ...
               dei2_dx0, dei2_dt0, dei1_dxf, dei2_dtf, dei2_dt, dei2_dp; ...
               def1_dx0, def1_dt0, def1_dxf, def1_dtf, def1_dt, def1_dp; ...
               def2_dx0, def2_dt0, def2_dxf, def2_dtf, def2_dt, def2_dp; ...
               def3_dx0, def3_dt0, def3_dxf, def3_dtf, def3_dt, def3_dp];
\end{verbatim}
\end{shadedframe}
\normalsize

\subsubsection{Syntax of Linkage Constraint Function Using Analytic Derivatives}

The syntax used to define the user defined vector of linkage
constraints between two phases is given as follows:
\begin{center}
\noindent{\bf function [links,Derivlinks]=mylinkfun(sollink);}
\end{center}
See Section \ref{sect:linkSyntax} for the definition of the regular inputs/outputs. The additional output of \slred{mylinkfun} is as follows:
\begin{itemize}
  \item \slred{Derivlinks}: a {\em matrix} of size $l\times (n^l+q^l+n^r+q^r)$
\end{itemize}
where $l$ is the number of linkages in the constraint, $n^l$ is the number of states in the left phase, $q^l$ is the number of parameters in the left phase, $n^r$ is the number of states in the right phase, and $q^r$ is the number of parameters in the right phase. The matrix \slred{Derivlinks} defines the partial derivatives of each linkage with respect to the left state, left parameters, right state, and right parameters:
\begin{center}
\noindent{\bf Derivlinks = $\left[\begin{array}{rrrr}
\displaystyle \pd{\bfP_1}{\bfx^l(t_f)}, &\quad \displaystyle\pd{\bfP_1}{p^l}, &\quad \displaystyle \pd{\bfP_1}{\bfx^r(t_0)}, &\quad \displaystyle\pd{\bfP_1}{p^r} \vspace{6pt}\\
 \vdots, &\quad \vdots, &\quad \vdots, &\quad \vdots \vspace{6pt}\\
\displaystyle \pd{\bfP_l}{\bfx^l(t_f)}, &\quad \displaystyle\pd{\bfP_l}{p^l}, &\quad \displaystyle \pd{\bfP_l}{\bfx^r(t_0)}, &\quad \displaystyle\pd{\bfP_l}{p^r}
\end{array}\right]$}
\end{center}
where $\bfP_i$, ($i = 1,\ldots,l$) is the $i^{th}$ linkage constraint. It is important to provide all the derivatives in the correct order {\em even if} they are zero.

\scriptsize
\begin{shadedframe}
{\noindent}{\bf Example of Linkage Constraint with Derivatives}
\vspace{12pt}

{\noindent}Suppose we have a multiple phase optimal control problem with a simple link between the phases, i.e. the state of the end of the phase is equal to the state at the beginning of the next phase.  \begin{displaymath}
\bfP = x^l(t_f) - x^r(t_0)
\end{displaymath}
Then the syntax of the above linkage is given as
\begin{verbatim}
function [links, Derivlinks] = mylinkagefun(sollink,left_phase,right_phase);

xf_left = sollink.left.state;
p_left  = sollink.left.parameter;
x0_right = sollink.right.state;
p_right  = sollink.right.parameter;

links = xf_left - x0_right;

nlink = length(xf_left); %number of linkages
Derivlinks = [ eye(nlink), zeros(nlink,length(p_left)), ...
              -eye(nlink), zeros(nlink,length(p_right))];
\end{verbatim}
\end{shadedframe}
\normalsize

\section{Output from an Execution of \gpops\label{sect:output}}

Upon execution of \gpops, new fields are created in the output structure
\slred{output}.  In particular, upon completion of the execution of
\gpops, the following new fields are created (in addition to the fields
that were created prior to running \gpops on the problem):
\begin{itemize}
  \item \bfblue{solution:}  an array of structures of length $P$
   (where $P$ is the number of phases) containing the solution in each phase
  \item \bfblue{solutionPlot:}  an array of structures of length $P$
   (where $P$ is the number of phases) containing a solution obtained
   using Lagrange polynomial interpolation that can be used for a
   graphical display of the solution (often because the structure
   \bfblue{solution} is obtained on a coarse grid due to the high
   accuracy of the pseudospectral method).  
\end{itemize}
The $p^{th}$ element in \bfblue{solution} contains the solution in
phase $p\in[1,\ldots,P]$.  The fields of \bfblue{solution} are as follows:
\begin{itemize}
 \item \bfblue{solution(\textit{p}).time:} a column vector containing
  the time at each discretization point along the trajectory.  
 \item \bfblue{solution(\textit{p}).state:} an array whose rows
  contain the state at each time point in
  \bfblue{solution(\textit{p}).time}.   
 \item \bfblue{solution(\textit{p}).control:} an array whose rows
 contain the control at each time point in \bfblue{solution(\textit{p}).time}.   
\item \bfblue{solution(\textit{p}).parameter:}  a column vector
  containing the static parameters.  
 \item \bfblue{solution(\textit{p}).costate:} an array whose rows
contain the costate at each time point in \bfblue{solution(\textit{p}).time}.   
 \item \bfblue{solution(\textit{p}).pathmult:} an array whose rows
contain the path constraint multipliers at each time point in
 \item \bfblue{solution(\textit{p}).Hamiltonian:} a column vector
   whose rows contain the Hamiltonian at each time point in 
\bfblue{solution(\textit{p}).time}.    
\item  \bfblue{solution(\textit{p}).Mayer\_cost:}  The Mayer part of the cost along the trajectory
\item  \bfblue{solution(\textit{p}).Lagrange\_cost:}  The Lagrange (integrated) cost along the trajectory
\end{itemize}
The $p^{th}$ element in \bfblue{solutionPlot} contains the solution in
phase $p\in[1,\ldots,P]$.  The fields of \bfblue{solutionPlot} are as follows:
\begin{itemize}
 \item \bfblue{solution(\textit{p}).time:} a column vector containing
  the time at each discretization point along the trajectory.  
 \item \bfblue{solution(\textit{p}).state:} an array whose rows
  contain the state at each time point in
  \bfblue{solution(\textit{p}).time}.   
 \item \bfblue{solution(\textit{p}).control:} an array whose rows
 contain the control at each time point in \bfblue{solution(\textit{p}).time}.   
\item \bfblue{solution(\textit{p}).costate:} an array whose rows
contain the costate at each time point in \bfblue{solution(\textit{p}).time}.   
\end{itemize}
It is noted that the field \bfblue{parameter} would be the same in
\bfblue{solutionPlot} as it is in \bfblue{solution} and thus,
\bfblue{parameter} is omitted from \bfblue{solutionPlot}.  

\section{Useful Information for Debugging a \gpops Problem}

One aspect of \gpops that may appear confusing when debugging
code pertains to the dimensions of the arrays and the corresponding
time values.  It is important to remember that \gpops uses
collocation at {\em Legendre-Gauss-Radau} points.  Because the
Legendre-Gauss-Radau points include the initial point but do not
include the final point, the dynamics, path constraints, and integrand
cost are computed only at the Legendre-Gauss-Radau points.  While this
may appear to be a bit strange, the fundamental point here is that
Legendre-Gauss-Radau quadrature (which is used in \gpops) only
evaluates the functions at the Legendre-Gauss-Radau points.  Do not
try to ``fool'' \gpops by adding the endpoints to the computation of
the dynamics, path constraints, or integrand cost.  If you do this,
you will get an error because the dimensions are incorrect.  For a
more complete mathematical description of the collocation method used
in \gpops, see the references on the Radau pseudospectral method as
given in the bibliography at the end of this manual. 

\section{\gpops Examples}

In this Chapter we provide three complete examples of using \gpops.  For
each example the optimal control problem is first described quantitatively,
then the \gpops code is provided.

\subsection{Hyper-Sensitive Problem}

\vspace{12pt}

Consider the following optimal control problem.  Minimize the cost functional
\begin{equation}
  J = \textstyle\frac{1}{2}\displaystyle \int_0^{t_f} \left( x^2 + u^2 \right) dt
\end{equation}
subject to the dynamic constraint
\begin{equation}
  \dx = -x^3 + u
\end{equation}
and the boundary conditions
\begin{equation}
  \begin{array}{lcl}
    x(0) & = & 1.5 \\
    x(t_f) & = & 1
  \end{array}
\end{equation}
with $t_f=50$.  It is noted that this problem is taken from Ref.~\citen{Rao1}.  The \gpops code that solves this problem
is shown below.  In particular, the following three MATLAB functions
are defined:
\begin{itemize}
  \item hyperSensitiveMain.m: MATLAB m-file (main driver) for problem
  \item hyperSensitiveCost.m: MATLAB function that evaluates the cost functional
  \item hyperSensitiveDae.m:  MATLAB function that evaluates the differential-algebraic equations
\end{itemize}
The beginning and end of each function is labeled by a MATLAB comment.
\scriptsize
\begin{shadedframe}
\verbatiminput{../examples/hyperSensitive/hyperSensitiveMain.m}
\verbatiminput{../examples/hyperSensitive/hyperSensitiveCost.m}
\verbatiminput{../examples/hyperSensitive/hyperSensitiveDae.m}
\end{shadedframe}
\normalsize 
The state, $x(t)$, control, $u(t)$, and costate, $\lambda(t)$
resulting from the execution of \gpops using the above code is
summarized in
Figs.~\ref{fig:hypersensitiveState}--\ref{fig:hypersensitiveCostate}.  

\begin{figure}[h]
 \centering
 \subfloat[State, $x(t)$, vs.~$t$.\label{fig:hypersensitiveState}]{\includegraphics[scale=0.45]{hypersensitiveState.pdf}}~~~~~\subfloat[Control, $u(t)$, vs.~$t$. \label{fig:hypersensitiveControl}]{\includegraphics[scale=0.45]{hypersensitiveControl.pdf}}

 \subfloat[Costate, $\lambda(t)$, vs.~$t$. \label{fig:hypersensitiveCostate}]{\includegraphics[scale=0.45]{hypersensitiveCostate.pdf}}

\caption{State,Control, and Costate for Hyper-Sensitive Optimal Control Problem}
\end{figure}

\clearpage

\subsection{Bryson-Denham Problem}

Consider the following optimal control problem.  Minimize the cost functional
\begin{equation}
  J = x_3(t_f)
\end{equation}
subject to the dynamic constraints
\begin{equation}
  \begin{array}{lcl}
    \dx_1 & = & x_2 \\
    \dx_2 & = & u \\
    \dx_3 & = & \frac{1}{2}u^2
  \end{array}
\end{equation}
the path constraint
\begin{equation}
  0 \leq x_1(t) \leq 1/9
\end{equation}
and the boundary conditions
\begin{equation}
  \begin{array}{lcl}
    x_1(0) & = & 0 \\
    x_2(0) & = & 1 \\
    x_3(0) & = & 0 \\
    x_1(t_f) & = & 0 \\
    x_2(t_f) & = & -1 \\
  \end{array}
\end{equation}
The above problem was originally formulated by Bryson and Denham \cite{Bryson2} and is referred to as the {\em Bryson-Denham} problem.  The
\gpops code that solves the Bryson-Denham problem is shown below.  In
particular, the following four MATLAB files are defined:
\begin{itemize}
  \item brysonDenhamMain.m: MATLAB m-file (main driver) for problem
  \item brysonDenhamCost.m: MATLAB function that evaluates the cost functional
  \item brysonDenhamDae.m: MATLAB function that evaluates the differential-algebraic equation
  \item brysonDenhamEvent.m: MATLAB function that evaluates the event constraints
\end{itemize}
The beginning and end of each function is labeled by a MATLAB
comment. It is noted that while all five boundary conditions are
simple bounds (and are, thus, linear, they are treated as general
event constraints in order to demonstrate the proper use of an event
function.
\scriptsize
\begin{shadedframe}
\verbatiminput{../examples/brysonDenham/brysonDenhamMain.m}
\verbatiminput{../examples/brysonDenham/brysonDenhamCost.m}
\verbatiminput{../examples/brysonDenham/brysonDenhamDae.m}
\end{shadedframe}
\normalsize
The output obtained by solving the Bryson-Denham problem using the
\gpops code above is summarized in
Figs.~\ref{fig:brysonDenhamState}--\ref{fig:brysonDenhamCostate}.  

\begin{figure}[t]
\centering
\subfloat[State vs.~Time.\label{fig:brysonDenhamState}]{\includegraphics[scale=0.45]{brysonDenhamState.pdf}}~~~~~\subfloat[Control vs.~Time. \label{fig:brysonDenhameControl}]{\includegraphics[scale=0.45]{brysonDenhamControl.pdf}}

\subfloat[Costate vs.~Time.\label{fig:brysonDenhamCostate}]{\includegraphics[scale=0.45]{brysonDenhamCostate.pdf}}
\end{figure}

\clearpage

\subsection{Multiple-Stage Launch Vehicle Ascent Problem}

The problem considered in this section is the ascent of a
multiple-stage launch vehicle.  The objective is to maneuver the launch
vehicle from the ground to the target orbit while maximizing the remaining
fuel in the upper stage.   It is noted that this example is taken
verbatim from Ref.~\citen{Benson1}.

\subsubsection{Vehicle Properties}

The launch vehicle considered in this example has two main stages
along with nine strap-on solid rocket boosters.  The flight of the
vehicle can be divided into {\em four} distinct phases.  The first
phase begins with the rocket at rest on the ground and at time $t_0$,
the main engine and six of the nine solid boosters ignite.  When the
boosters are depleted at time $t_1$, their remaining dry mass is
jettisoned. The final three boosters are then ignited, and along with the
main engine, represent the thrust for the second phase of flight.
These three remaining boosters are jettisoned when their fuel is
exhausted at time $t_2$, and the main engine alone creates the thrust
for the third phase.   The fourth phase begins when the main engine
fuel has been exhausted (MECO) and the dry mass associated with the
main engine is ejected at time $t_3$.   The thrust during phase four
is from a second stage, which burns until the target orbit has been
reached (SECO) at time $t_4$, thus completing the trajectory.  The
specific characteristics of these rocket motors can be seen in Table
\ref{table: launch vehicle properties}.  Note that the solid boosters
and main engine burn for their entire duration (meaning $t_1$, $t_2$,
and $t_3$ are fixed), while the second stage engine is shut off when
the target orbit is achieved ($t_4$ is free).

\begin{table}[htdp]
\centering
\caption{Mass and propulsion properties of the launch vehicle ascent
  problem. \label{table: launch vehicle properties}}
\begin{tabular}{|c|c|c|c|}
\hline
 & Solid Boosters & Stage 1 & Stage 2 \\
 \hline \hline
 Total Mass (kg) & 19290 & 104380 & 19300 \\
 \hline
 Propellant Mass (kg) & 17010 & 95550 & 16820 \\
 \hline
 Engine Thrust (N) & 628500 & 1083100 & 110094 \\
 \hline
 Isp (sec) & 284 & 301.7 & 462.4 \\
 \hline
 Number of Engines & 9 & 1 & 1 \\
 \hline
 Burn Time (sec) & 75.2 & 261 & 700 \\
 \hline
\end{tabular}
\end{table}

\subsubsection{Dynamic Model}

The equations of motion for a non-lifting point mass in flight over a
spherical rotating planet are expressed in Cartesian Earth centered inertial
(ECI) coordinates as
\begin{equation}\label{dyncs}
\begin{array}{rcl}
  \dot{\textbf{r}} &=& {\bf v} \vspace{3pt}\\
  \dot{\textbf{v}} &=& -\displaystyle\frac{\mu}{\|\textbf{r}\|^3}{\bf r} +
  \displaystyle\frac{T}{m}{\bf u} + \displaystyle\frac{{\bf D}}{m}  \vspace{3pt}\\
  \dot{m} & = & -\displaystyle\frac{T}{g_0I_{sp}}
\vspace{3pt}\\
\end{array}
\end{equation}
where ${\bf r}(t)=\left[\begin{array}{ccc} x(t) & y(t) & z(t)\end{array}\right]^T$
is the position, ${\bf v} = \left[\begin{array}{ccc} v_x(t) & v_y(t) & v_z(t)\end{array}\right]^T$
is the Cartesian ECI velocity, $\mu$ is the gravitational parameter, $T$ is
the vacuum thrust, $m$ is the mass, $g_0$ is the acceleration due to gravity at sea level,
$I_{sp}$ is the specific impulse of the engine,
${\bf u} = \left[\begin{array}{ccc} u_x & u_y & u_z \end{array}\right]^T$ is the thrust
direction, and ${\bf D}=\left[\begin{array}{ccc} D_x & D_y & D_z \end{array}\right]^T$
is the drag force.  The drag force is defined as
\begin{equation}
  {\bf D} = -\frac{1}{2}C_D A_{ref}\rho \|{\bf v}_{rel}\|{\bf v}_{rel}
\end{equation}
where $C_D$ is the drag coefficient, $A_{ref}$ is the reference area, $\rho$
is the atmospheric density, and ${\bf v}_{rel}$ is the Earth relative
velocity, where ${\bf v}_{rel}$ is given as
\begin{equation}
{\bf v}_{rel} = {\bf v}-\boldsymbol{\omega} \times {\bf r}
\end{equation}
where $\boldsymbol\omega$ is the angular velocity of the Earth relative to
inertial space.  The atmospheric density is modeled as the exponential
function
\begin{equation}
\rho = \rho_0\mbox{exp}[-h/h_0]
\end{equation}
where $\rho_0$ is the atmospheric density at sea level, $h=\|\bfr\|-R_e$ is
the altitude, $R_e$ is the equatorial radius of the Earth, and $h_0$ is the
density scale height.  The numerical values for these constants can be found
in Table \ref{dynamics properties}.

%This dynamic model has many simplifying assumptions.  First, the thrust from
%each engine is assumed to be the vacuum thrust.  This results in a constant
%thrust magnitude that does not depend on atmospheric pressure.  Second, the
%reference area and coefficient of drag are constant for the entire trajectory,
%with no dependence on Mach number or angle of attack.  Third, the drag is
%assumed to always oppose the relative velocity.  There is no component of
%lift, and the drag has no dependence on vehicle orientation.  Lastly, the
%Earth is modeled as a perfect sphere.   These assumptions allow the dynamic
%equations to be the same for each phase of the trajectory, where only the
%thruster characteristics change between phases.

\begin{table}[htdp]
\caption{Constants used in the launch vehicle example.}
\begin{center}
\begin{tabular}{|c|c|}
\hline
Constant & Value \\
\hline \hline
Payload Mass (kg) & 4164 \\
\hline
$A_{ref}$ (m${}^2$) & $4\pi$ \\
\hline
$C_d$ & 0.5 \\
\hline
$\rho_0$ (kg/m${}^3$)& 1.225 \\
\hline
$h_0$ (km) & 7.2\\
\hline
$t_1$ (s) & 75.2 \\
\hline
 $t_2$ (s) & 150.4 \\
\hline
 $t_3$ (s) & 261 \\
\hline
 $R_e$ (km) & 6378.14 \\
\hline
 $V_E$ (km/s) & 7.905\\
\hline
\end{tabular}
\end{center}
\label{dynamics properties}
\end{table}

\subsubsection{Constraints}

The launch vehicle starts on the ground at rest (relative to the Earth) at time $t_0$, so that the ECI initial conditions are
\begin{equation}\label{ICs}
\begin{array}{rcl}
{\bf r}(t_0) &=& {\bf r}_0 = \left[ \begin{array}{ccc} 5605.2 & 0 & 3043.4 \end{array} \right] ^T\quad \mbox{km} \vspace{3pt}\\
{\bf v}(t_0) &=& {\bf v}_0 = \left[ \begin{array}{ccc} 0 & 0.4076 & 0 \end{array} \right]^T \quad \mbox{km/s} \vspace{3pt}\\
m(t_0) &=& m_0 = 301454 \quad \mbox{kg}
\end{array}
\end{equation}
which corresponds to the Cape Canaveral launch site.  The terminal constraints
define the target geosynchronous transfer orbit (GTO), which is defined in
orbital elements as
\begin{equation}\label{FCs}
\begin{array}{rcl}
 a_f &=   &  24361.14 \; \mbox{km}, \\
 e_f &=   &  0.7308, \\
 i_f &=   &  28.5\deg,\\
 \Omega_f &= & 269.8\deg, \\
 \omega_f &= & 130.5\deg
\end{array}
\end{equation}
The orbital elements, $a,e,i,\Omega$, and $\omega$ represent the semi-major
axis, eccentricity, inclination, right ascension of the ascending node
(RAAN), and argument of perigee, respectively.  Note that the true anomaly,
$\nu$, is left undefined since the exact location within the orbit is not
constrained.  These orbital elements can be transformed into ECI coordinates
via the transformation, $T_{o2c}$, where $T_{o2c}$ is given in \cite{Bate1}.

In addition to the boundary constraints, there exists both a state path
constraint and a control path constraint in this problem.  A state path
constraint is imposed to keep the vehicle's altitude above the surface of the
Earth, so that
\begin{equation}\label{xpath}
|{\bf r}|\geq R_r
\end{equation}
where $R_e$ is the radius of the Earth, as seen in Table \ref{dynamics
  properties}.  Next, a path constraint is imposed on the control to guarantee
that the control vector is unit length, so that
\begin{equation}\label{upath}
|{\bf u}| = 1
\end{equation}

Lastly, each of the four phases in this trajectory is linked to the adjoining phases by a set of linkage conditions.  These constraints force the position and velocity to be continuous and also account for the mass ejections, as
\begin{equation}
\begin{array}{rcl}
{\bf r}^{(p)}(t_f)-{\bf r}^{(p+1)}(t_0) &=& {\bf 0}, \\
{\bf v}^{(p)}(t_f)-{\bf v}^{(p+1)}(t_0) &=& {\bf 0}, \qquad (p=1,\ldots,3)\\
m^{(p)}(t_f)-m_{dry}^{(p)}-m^{(p+1)}(t_0) &=& 0 \\
\end{array}
\end{equation}
where the superscript $(p)$ represents the phase number.

The optimal control problem is then to find the control, ${\bf u}$,
that minimizes the cost function
\begin{equation}
  J=-m^{(4)}(t_f)
\end{equation}
subject to the conditions of Eqs.~(\ref{dyncs}), (\ref{ICs}), (\ref{FCs}),
(\ref{xpath}), and (\ref{upath}).

The MATLAB code that solves the multiple-stage launch vehicle ascent
problem using \gpops is shown below.  In particular, this
problem requires the specification of a function that computes the
cost functional, the differential-algebraic equations (which, it is
noted, include both the differential equations {\em and} the path
constraints), and the event constraints in each phase of the problem
along with the phase-connect (\ie linkage) constraints.  The problem
was posed in SI units and the built-in autoscaling procedure was
used.
\scriptsize
\begin{shadedframe}
\verbatiminput{../examples/launch/launchMain.m}
\verbatiminput{../examples/launch/launchCost.m}
\verbatiminput{../examples/launch/launchDae.m}
\verbatiminput{../examples/launch/launchEvent.m}
\verbatiminput{../examples/launch/launchrv2oe.m}
\verbatiminput{../examples/launch/launchoe2rv.m}
\end{shadedframe}
\normalsize
The output of the above code from \gpops is summarized in the following three
plots that contain the altitude, speed, and controls.
\begin{figure}[h]
\centering
\subfloat[Altitude vs.~Time.\label{fig:launchAltitude}]{\includegraphics[scale=0.45]{launchAltitude.pdf}}~~~~~\subfloat[Speed vs.~Time. \label{fig:launchSpeed}]{\includegraphics[scale=0.45]{launchSpeed.pdf}}

\subfloat[Mass vs.~Time.\label{fig:launchMass}]{\includegraphics[scale=0.45]{launchMass.pdf}}~~~~~\subfloat[Control vs.~Time. \label{fig:launchControl}]{\includegraphics[scale=0.45]{launchControl.pdf}}
\end{figure}

\clearpage

\subsection{Minimum Time-to-Climb of a Supersonic Aircraft}

The problem considered in this section is the classical minimum
time-to-climb of a supersonic aircraft.  The objective is to determine
the minimum-time trajectory and control from take-off to a specified
altitude and speed.  This problem was originally stated in the open
literature in the work of Ref.~\citen{Bryson1}, but the model used in
this study was taken from Ref.~\citen{Betts1} with the exception that
a linear extrapolation of the thrust data as found in
Ref.~\citen{Betts1} was performed in order to fill in the ``missing'' 
data points.

The minimum time-to-climb problem for a supersonic aircraft is posed
as follows.  Minimize the cost functional
\begin{equation}
  J = t_f
\end{equation}
subject to the dynamic constraints
\begin{eqnarray}
  \dot{h} & = & v\sin\alpha \\
  \dot{v} & = & \frac{T\cos\alpha-D}{m} \\
 \dot{\gamma} & = & \frac{T\sin\alpha+L}{mv}+\left(\frac{v}{r}-\frac{\mu}{vr^2}\right)\cos\gamma\\
 \dot{m} & =&  -\frac{T}{g0 I_{sp}} 
\end{eqnarray}
and the boundary conditions
\begin{eqnarray}
  h(0) & = & 0 \textrm{ ft} \\
  v(0) & = & 129.3144 \textrm{ m/s} \\
  \gamma(0) & = & 0 \textrm{ rad} \\
  h(t_f) & = & 19994.88 \textrm{ m} \\
  v(t_f) & = & 295.092 \textrm{ ft/s} \\
  \gamma(t_f) & = & 0 \textrm{ rad}
\end{eqnarray}
where $h$ is the altitude, $v$ is the speed, $\gamma$ is the
flight path angle, $m$ is the vehicle mass, $T$ is the magnitude of
the thrust force, and $D$ is the magnitude of the drag force.  It is
noted that this example uses table data obtained from
Ref.~\citen{Bryson1}.  In this example \gpops is implemented using the
finite-difference derivative option (that is, using the option
\slred{setup}.\bfblue{derivatives}='finite-difference') together with an interpolation of the
table data with the MATLAB functions 'interp1' and 'interp2'.   The
MATLAB code that solves the minimum time-to-climb of a supersonic 
aircraft is shown below.
\scriptsize
\begin{shadedframe}
\verbatiminput{../examples/brysonMinimumClimb/brysonMinimumClimbMain.m}
\verbatiminput{../examples/brysonMinimumClimb/brysonMinimumClimbCost.m}
\verbatiminput{../examples/brysonMinimumClimb/brysonMinimumClimbDae.m}
\verbatiminput{../examples/brysonMinimumClimb/brysonMinimumClimbDae.m}
\end{shadedframe}
\normalsize
The components of the state and the control obtained from running the
above \gpops code is summarized in 
Figs.~\ref{fig:brysonMinClimbAltitude}--\ref{fig:brysonMinClimbAttackAngle}.  
\begin{figure}[h]
\centering
\subfloat[Altitude vs.~Time.\label{fig:brysonMinClimbAltitude}]{\includegraphics[scale=0.45]{brysonMinClimbAltitude.pdf}}~~~~~\subfloat[Speed vs.~Time. \label{fig:brysonMinClimbSpeed}]{\includegraphics[scale=0.45]{brysonMinClimbSpeed.pdf}}

\subfloat[Flight Path Angle vs.~Time.\label{fig:brysonMinClimbFlightPathAngle}]{\includegraphics[scale=0.45]{brysonMinClimbFlightPathAngle.pdf}}~~~~~\subfloat[Mass vs.~Time. \label{fig:brysonMinClimbMass}]{\includegraphics[scale=0.45]{brysonMinClimbMass.pdf}}

\subfloat[Angle of Attack vs.~Time.\label{fig:brysonMinClimbAttackAngle}]{\includegraphics[scale=0.45]{brysonMinClimbAttackAngle.pdf}}
\end{figure}

\clearpage

\section{Concluding Remarks}

While the authors have put for the effort to make \gpops a
user-friendly software, it is important to understand several aspects
of computational optimal control in order to make \gpops easier to
use.  First, it is {\em highly} recommended that the user scale a
problem manually using insight from the physics/mathematics of the
problem because the automatic scaling procedure is by no means
foolproof.  Second, the particular parameterization of a problem can
make all the difference with regard to obtaining a solution in a
reliable manner.  Finally, even if the NLP solver returns the result that the
optimality conditions have been satisfied, it is important to verify
the solution.  In short, a great deal of time in solving optimal
control problems is spent in formulation and analysis.

\bibliographystyle{aiaa}
\bibliography{master2}

\end{document}
